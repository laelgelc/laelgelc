{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"http://corpuslg.org/lael_english/wp-content/uploads/2020/04/lael_50_years_narrow_white.png.400px_300dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Images function set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f45250f-188e-4d39-91ed-635f368b0e0d",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b2be7-329a-40ec-818c-e78e99371bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bcd50d-04ff-4428-af11-4e576a37e7dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preamble (Do not execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3619e9-f7d1-4a0b-bb1c-c5c8b9fe7565",
   "metadata": {},
   "source": [
    "- Group number definition\n",
    "- Selects the syntax of the the commands 'shuf' and 'sed' for Mac or Linux platforms\n",
    "- The variables 'myshuf' and 'mysed' are not used in the programme\n",
    "- Decision: comment it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7e0af-51f7-4240-8007-d1fe8f137838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter your group number\n",
    "#group=4\n",
    "\n",
    "#enter the label for your system, mac or linux\n",
    "#mysystem=mac\n",
    "#mysystem=linux\n",
    "\n",
    "#  if [ \"$mysystem\" == mac ]\n",
    "#    then\n",
    "#    myshuf=gshuf\n",
    "#    mygsed=gsed\n",
    "#  else\n",
    "#    myshuf=shuf\n",
    "#    mygsed=sed\n",
    "#  fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0292236-2255-412d-a679-09742685cb26",
   "metadata": {},
   "source": [
    "## 'presample' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0138bce-308d-4681-aee8-655e7aea3074",
   "metadata": {},
   "source": [
    "- Processes 'tweets/scraped.txt' into 'images/presample.txt'\n",
    "- Correction to create the folder 'images' for the first tine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143408f-9e27-4e02-8ca5-c7dbd15e05ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01855a-1bfd-493f-85d5-ce70e5891b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "presample () {\n",
    "\n",
    "mkdir -p images\n",
    "\n",
    "grep fullUrl tweets/scraped.txt | cut -f2- | nl | sed 's/^[ ]*//' > images/presample.txt\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad1c55-684c-4827-ad80-175716b71928",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9776ac-9b61-451d-8e5b-5b4d328d339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['wsl', './presample.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b865a3e-b03d-4117-8138-3129d0daef08",
   "metadata": {},
   "source": [
    "## 'collecturls' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549cf86b-2c6b-45c9-9de3-444d3c9b9ec4",
   "metadata": {},
   "source": [
    "- Processes 'images/presample.txt' into 'images/images_index.txt'\n",
    "- Defines 13 image batches with 1000 images in each batch\n",
    "- Creates one folder for each batch in 'images/images'\n",
    "- The commands 'rg' and 'jq' are required\n",
    "- Correction to resolve folder naming conflict with 'grabimages' function\n",
    "    - from: 'sort z | uniq > folders'\n",
    "    - to: 'sort z | uniq | sed 's/fl://' > folders'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57c540-3ff5-42a1-80a5-bfe88a8b3f6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbeca2-f794-4f27-a922-63fe352005de",
   "metadata": {},
   "outputs": [],
   "source": [
    "getimagesurls () {\n",
    "\n",
    "last=$( cat images/presample.txt | wc -l | tr -dc '[0-9]' )\n",
    "\n",
    "#mkdir -p images\n",
    "\n",
    "rm -f images/urls.txt  ### WATCH THIS!\n",
    "\n",
    "for i in $(eval echo {1..$last});\n",
    "do\n",
    "        rg -m1 \"^\"$i\"\t\" images/presample.txt | jq '.' > z\n",
    "        file=$( grep -m1 'fullUrl' z | cut -d'\"' -f4  )\n",
    "        format=$( echo $file | tr '?&=' '|' | cut -d'|' -f3 )\n",
    "        id=$( grep -m1 'id\"' z | tr '~' ' ' | sed -e 's/^[ ]*//' -e 's/:/~/' | cut -d'~' -f2 | tr -dc '[0-9]' )\n",
    "        username=$( grep -m1 'username\"' z | tr '~' ' ' | sed -e 's/^[ ]*//' -e 's/:/~/' | cut -d'~' -f2 | sed -e 's/\"//' -e 's/^[ ]*//' -e 's/\",$//' | tr '[:upper:]' '[:lower:]' )\n",
    "        date=$( grep -m1 'date\"' z | tr '~' ' ' | sed -e 's/^[ ]*//' | cut -d'~' -f2 | cut -d'T' -f1 | tr -dc '[0-9-]' )\n",
    "\n",
    "        echo \"---- collecturls $i / $last ----\"\n",
    "\n",
    "        echo \"id:\"$id\"|d:$date|u:\"$username\"|i:$file|f:$format\" >> images/urls.txt\n",
    "done \n",
    "\n",
    "grep 'id:...................|' images/urls.txt | nl -nrz | sed 's/^/t:/' | tr '\\t' '|' > w\n",
    "\n",
    "for n in `seq -w 1 13`  # how many batches\n",
    "do\n",
    "  printf \"$n\\n%.0s\" {1..1000}  # how many lines in each batch\n",
    "done | sed 's/^/fl:/' > z\n",
    "\n",
    "paste z w | tr '\\t' '|' | grep 'id:' > images/images_index.txt\n",
    "\n",
    "#sort z | uniq > folders\n",
    "sort z | uniq | sed 's/fl://' > folders\n",
    "while read folder\n",
    "do\n",
    "    mkdir -p images/images/$folder\n",
    "done < folders\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa6a380-9deb-4cfb-bc8d-6add86fbb671",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e4f6e-f2a7-450d-8fb5-89109b1d7ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subprocess.run(['wsl', './getimagesurls.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563469c-965c-4f22-b71f-dfc71d4d97fa",
   "metadata": {},
   "source": [
    "## 'grabimages' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dfd915-32b1-40d5-96de-cd3ece1c25b9",
   "metadata": {},
   "source": [
    "- Processes 'images/images_index.txt' into ''\n",
    "- The command 'curl' is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734261d5-172d-4718-98fc-cdee1442ee69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ad421-84fc-4938-b089-c9b2916f8183",
   "metadata": {},
   "outputs": [],
   "source": [
    "grabimages () {\n",
    "\n",
    "last=$( cat images/images_index.txt | wc -l | tr -cd '[0-9]' )\n",
    "\n",
    "for i in $(eval echo {1..$last});\n",
    "do\n",
    "    sed -n \"$i\"p images/images_index.txt > z\n",
    "    folder=$( cut -d'|' -f1 z | sed 's/fl://' )\n",
    "    n=$( cut -d'|' -f2 z | sed 's/t://' )\n",
    "    id=$( cut -d'|' -f3 z | sed 's/id://' )\n",
    "    file=$( cut -d'|' -f6 z | sed 's/i://' )\n",
    "    ext=$( cut -d'|' -f7 z | sed 's/f://' )\n",
    "    \n",
    "    echo \"---- fetching image $n / $last ----\"\n",
    "    \n",
    "    curl -k \"$file\" > images/images/\"$folder\"/\"$n\".\"$ext\"\n",
    "done \n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8844d20-080a-4231-99fb-5efa7305283d",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a3c60-a0dd-4444-9b07-1c6739db7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['wsl', './grabimages.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e585608-98b2-4d9d-92dc-8b8b1cdcd9ad",
   "metadata": {},
   "source": [
    "## 'removedupes' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf83a74-d783-480f-92cf-7d6510a0dad5",
   "metadata": {},
   "source": [
    "- Removes duplicate images posted in the same message or in repeated messages by the same user (same message id)\n",
    "- The function was empirically tested by manually introducing a duplicate image-containing message in 'tweets/scraped.txt' and it works as expected. It returns the following error message that apparently does not harm its functionality\n",
    "    - './removedupes.sh: line 27: remove: No such file or directory\\ngrep: remove: No such file or directory\\nfind: paths must precede expression: `empty'\\n'\n",
    "- When there are no duplicates, the function ends with the following error message. This result is not harmful because it proves that there are no duplicates\n",
    "    - './removedupes.sh: line 27: remove: No such file or directory\\ngrep: remove: No such file or directory\\nfind: paths must precede expression: `empty'\\n'\n",
    "- Correction to avoid 'images/images_index.txt' to have all lines excluded in case thare are no duplicates and, thus, the 'remove' file is empty\n",
    "- Correction to avoid an error condition in case there are no duplicates and the file 'remove' is not generated\n",
    "- Correction from 'find images/images -type f empty -exec rm {} +' to 'find images/images -type f -empty -exec rm {} +'\n",
    "- Correction from 'cat i i f | sort | uniq -c | grep ' 2 ' | cut -c6- | grep -v '^$' | sed 's/^/t:/' > ionly' to 'cat i i f | sort | uniq -c | grep ' 2 ' | cut -c9- | grep -v '^$' | sed 's/^/t:/' > ionly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7643a02-a754-4c58-b745-891a35b65c89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e209507-1085-4c86-b5cd-3cd054cf7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "removedupes () {\n",
    "\n",
    "# remove duplicate images posted in the same message or in repeated messages by the same user (same message id)\n",
    "    \n",
    "cut -d'|' -f3 images/images_index.txt | sed 's/id://' | sort | uniq -c | grep -v ' 1 ' | nl | sed 's/^[ ]*//' | tr '\\t' ' ' | tr -s ' ' > d\n",
    "\n",
    "rm -f remove\n",
    "\n",
    "while read n maxhits id\n",
    "do\n",
    "    echo \"--- listing $n ---\"\n",
    "    grep -m$maxhits $id images/images_index.txt | cut -d'|' -f6 | sort | uniq -d | sed 's/i://' > dupes\n",
    "    \n",
    "    while read dupe\n",
    "    do\n",
    "        grep $dupe images/images_index.txt | tail +2 | cut -d'|' -f2\n",
    "    done < dupes >> remove\n",
    "done < d \n",
    "\n",
    "# remove duplicate image files\n",
    "#while read dupe\n",
    "#do\n",
    "#    pretty=$( echo $dupe | sed 's/t://' )\n",
    "#    folder=$( grep $dupe images/images_index.txt | cut -d'|' -f1 | sed 's/fl://' )\n",
    "#    ext=$( grep $dupe images/images_index.txt | cut -d'|' -f7 | sed 's/f://' )\n",
    "#    rm -f images/images/\"$folder\"/\"$pretty\".\"$ext\"\n",
    "#    echo \"--- removing images/images/\"$folder\"/\"$pretty\".\"$ext\" ---\"\n",
    "#done < remove\n",
    "if [[ -s remove ]]; then\n",
    "    while read dupe\n",
    "    do\n",
    "        pretty=$( echo $dupe | sed 's/t://' )\n",
    "        folder=$( grep $dupe images/images_index.txt | cut -d'|' -f1 | sed 's/fl://' )\n",
    "        ext=$( grep $dupe images/images_index.txt | cut -d'|' -f7 | sed 's/f://' )\n",
    "        rm -f images/images/\"$folder\"/\"$pretty\".\"$ext\"\n",
    "        echo \"--- removing images/images/\"$folder\"/\"$pretty\".\"$ext\" ---\"\n",
    "    done < remove\n",
    "fi\n",
    "\n",
    "# remove dupes from index\n",
    "#grep -vf remove images/images_index.txt > z ; mv z images/images_index.txt\n",
    "if [[ -s remove ]]; then\n",
    "    grep -vf remove images/images_index.txt > z ; mv z images/images_index.txt\n",
    "fi\n",
    "\n",
    "# remove dupes from index again, for some reason some still remain\n",
    "cut -d'|' -f2  images/images_index.txt | cut -d':' -f2 > i\n",
    "find images/images -type f | cut -d'/' -f4 | cut -d'.' -f1 > f\n",
    "cat i i f | sort | uniq -c | grep ' 2 ' | cut -c9- | grep -v '^$' | sed 's/^/t:/' > ionly\n",
    "grep -vf ionly images/images_index.txt > b ; mv b images/images_index.txt\n",
    "\n",
    "# remove empty image files\n",
    "find images/images -type f -empty -exec rm {} +\n",
    "\n",
    "# remove empty image files from index\n",
    "cut -d'|' -f2  images/images_index.txt | cut -d':' -f2 > i\n",
    "find images/images -type f | cut -d'/' -f4 | cut -d'.' -f1 > f\n",
    "cat i i f | sort | uniq -c | grep ' 2 ' | cut -c9- | grep -v '^$' | sed 's/^/t:/' > ionly\n",
    "grep -vf ionly images/images_index.txt > b ; mv b images/images_index.txt\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4b08e-b98c-4a4f-928d-da3bdc2533e1",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414bc00-b04e-4402-b3c9-acfe32e513b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['wsl', './removedupes.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a6686-4bd0-4f3b-8781-cccd41de4c77",
   "metadata": {},
   "source": [
    "## 'uploadtobucket' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641d3fe-5a66-4007-bb82-5fe5d62a4116",
   "metadata": {},
   "source": [
    "- Copies the 'images/images' folder to the user's Google Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cc347-23f2-436a-8f81-1cbc545f5a73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705087af-4a6b-427c-8de2-ad68cea4d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploadtobucket () {\n",
    "\n",
    "# google cloud gsutil account = tonyberber@gmail.com\n",
    "\n",
    "gcloud alpha storage cp -R images/images gs://socialmediaclassimages/group\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc709e3-4f0c-451b-bd45-6d998acbfb7a",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f809b-05c4-46ed-9def-d94d1f4502c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Using Google Cloud SDK Shell (Do not execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728b0bc-80f1-4cec-a552-82cb3ccb3fca",
   "metadata": {},
   "source": [
    "- On your Desktop, click on 'Google Cloud SDK Shell'\n",
    "- On the terminal window execute the commands as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca86c1-71fd-468d-ba3f-9d57529fc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the folder where the 'images' folder is located\n",
    "C:\\Users\\eyamr\\AppData\\Local\\Google\\Cloud SDK>cd C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground\n",
    "C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground>dir\n",
    " Volume in drive C is OS\n",
    " Volume Serial Number is FA6F-4E60\n",
    "\n",
    " Directory of C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground\n",
    "\n",
    "20/09/2023  17:43    <DIR>          .\n",
    "19/09/2023  15:29    <DIR>          ..\n",
    "<omitted>\n",
    "20/09/2023  17:37    <DIR>          images\n",
    "<omitted>\n",
    "              24 File(s)         51.289 bytes\n",
    "               5 Dir(s)  134.018.973.696 bytes free\n",
    "\n",
    "# List the buckets\n",
    "C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground>gcloud storage ls\n",
    "gs://laelimages/\n",
    "\n",
    "# Run the following commad\n",
    "C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground>gcloud alpha storage cp -R images/images gs://laelimages\n",
    "Copying file://images\\images\\01\\000001.jpg to gs://laelimages/images/01/000001.jpg\n",
    "Copying file://images\\images\\01\\000002.jpg to gs://laelimages/images/01/000002.jpg\n",
    "  Completed files 2/2 | 159.3kiB/159.3kiB\n",
    "\n",
    "Average throughput: 6.0MiB/s\n",
    "\n",
    "C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e5460-4a2e-4315-a204-b8d8cf672526",
   "metadata": {},
   "source": [
    "#### Using the 'google-cloud-storage' Python library\n",
    "Alternative 1: Completely equivalent to the Google Cloud SDK approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed692ca-55ef-47e4-9d2e-f675ca781b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_directory_to_bucket(bucket_name, source_directory, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            blob_path = os.path.join(destination_blob_name, os.path.relpath(local_path, source_directory)).replace('\\\\', '/')\n",
    "            blob = bucket.blob(blob_path)\n",
    "            blob.upload_from_filename(local_path)\n",
    "\n",
    "    print(f'Directory {source_directory} uploaded to {bucket_name}/{destination_blob_name} successfully!')\n",
    "\n",
    "end = False\n",
    "while end == False:\n",
    "    my_bucket = str(input('Enter your bucket name: '))\n",
    "    if my_bucket != '':\n",
    "        bucket_name = my_bucket\n",
    "        end = True\n",
    "        clear_output()\n",
    "\n",
    "source_directory = r'.\\images\\images'\n",
    "destination_blob_name = 'images'\n",
    "upload_directory_to_bucket(bucket_name, source_directory, destination_blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46be61-6ac2-486d-abec-e82f0fbc0f77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Using the 'google-cloud-storage' Python library (Do not execute)\n",
    "Alternative 2: Copying even empty subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5e154-3743-45d5-a189-7d338c0392a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_directory_to_bucket(bucket_name, source_directory, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            blob_path = os.path.join(destination_blob_name, os.path.relpath(local_path, source_directory)).replace('\\\\', '/')\n",
    "            blob = bucket.blob(blob_path)\n",
    "            blob.upload_from_filename(local_path)\n",
    "\n",
    "        for dir in dirs:\n",
    "            dir_path = os.path.join(destination_blob_name, os.path.relpath(os.path.join(root, dir), source_directory)).replace('\\\\', '/')\n",
    "            blob = bucket.blob(dir_path + '/')\n",
    "            blob.upload_from_string('')\n",
    "\n",
    "    print(f'Directory {source_directory} uploaded to {bucket_name}/{destination_blob_name} successfully!')\n",
    "\n",
    "end = False\n",
    "while end == False:\n",
    "    my_bucket = str(input('Enter your bucket name: '))\n",
    "    if my_bucket != '':\n",
    "        bucket_name = my_bucket\n",
    "        end = True\n",
    "        clear_output()\n",
    "\n",
    "source_directory = r'.\\images\\images'\n",
    "destination_blob_name = 'images'\n",
    "upload_directory_to_bucket(bucket_name, source_directory, destination_blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cbfce-704b-4e16-bce8-3ff9af1e134d",
   "metadata": {},
   "source": [
    "## 'googlelabels' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f88f6-dff7-4b07-a74e-d1543374af77",
   "metadata": {},
   "source": [
    "- Detects the labels of the images with Google Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83b477-aeef-41f2-995c-c5b58abe754e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e9bb3-0dda-4b71-963b-e17e07f2305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "googlelabels () {\n",
    "\n",
    "# speed: 1 file per second\n",
    "\n",
    "while read folder\n",
    "do\n",
    "  mkdir -p images/google_cloud/labels/$folder\n",
    "  ### rm -f images/google_cloud/labels/$folder/*\n",
    "done < folders\n",
    "\n",
    "last=$( tail -1 images/images_index.txt | cut -d'|' -f2 | sed 's/t://'  )\n",
    "\n",
    "for i in $(eval echo {1..$last});\n",
    "do\n",
    "    sed -n \"$i\"p images/images_index.txt > z\n",
    "    folder=$( cut -d'|' -f1 z | sed 's/fl://' )\n",
    "    n=$( cut -d'|' -f2 z | sed 's/t://' )\n",
    "    id=$( cut -d'|' -f3 z | sed 's/id://' )\n",
    "    file=$( cut -d'|' -f6 z | sed 's/i://' )\n",
    "    ext=$( cut -d'|' -f7 z | sed 's/f://' )\n",
    "    \n",
    "    echo \"---- detect-labels $i / $last ----\"\n",
    "    \n",
    "    gcloud ml vision detect-labels --max-results=150  gs://socialmediaclassimages/group/\"$folder\"/\"$n\".\"$ext\" > images/google_cloud/labels/\"$folder\"/\"$n\".txt\n",
    "    \n",
    "done \n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d051d4-2312-4c42-834f-8299ecc4b1e5",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e99f3a-466f-4add-8f19-746bdc12abbb",
   "metadata": {},
   "source": [
    "#### Using the 'google-cloud-vision' Python library\n",
    "It is a Python code that is functionally equivalent to the original shell script (so it is a valid artefact) but it generates an output file format that may be incompatible with the subsequent shell scripts in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399956e-ad28-41a7-9d9b-047e38c740a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_labels(image_uri):\n",
    "    \"\"\"Detects labels in the image URL using the Google Cloud Vision API.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = image_uri\n",
    "    response = client.label_detection(image = image, max_results = 150)\n",
    "    if response.error.message:\n",
    "        raise Exception(f'Error: {response.error.message}')\n",
    "    return response.label_annotations\n",
    "\n",
    "with open('folders', 'r') as f:\n",
    "    for folder in f:\n",
    "        folder = folder.strip()\n",
    "        os.makedirs(f'images/google_cloud/labels/{folder}', exist_ok = True)\n",
    "        # os.system(f'rm -f images/google_cloud/labels/{folder}/*')\n",
    "\n",
    "last = subprocess.run(['wsl', 'tail', '-1', 'images/images_index.txt'], capture_output = True, text = True).stdout.strip().split('|')[1][2:]\n",
    "last = int(last)\n",
    "\n",
    "for i in range(1, last + 1):\n",
    "    try:\n",
    "        with open('images/images_index.txt', 'r') as f:\n",
    "            line = next(line for j, line in enumerate(f, start = 1) if j == i)\n",
    "            folder = line.split('|')[0][3:]\n",
    "            n = line.split('|')[1][2:]\n",
    "            id = line.split('|')[2][3:]\n",
    "            file = line.split('|')[5][2:]\n",
    "            ext = line.split('|')[6][2:5]\n",
    "\n",
    "        print(f\"---- detect-labels {i} / {last} ----\")\n",
    "\n",
    "        image_uri = f'gs://{bucket_name}/images/{folder}/{n}.{ext}'\n",
    "        labels = detect_labels(image_uri)\n",
    "        with open(f'images/google_cloud/labels/{folder}/{n}.txt', 'w') as f:\n",
    "            for label in labels:\n",
    "                f.write('description: ' + f'{label.description}\\n')\n",
    "                f.write('mid: ' + f'{label.mid}\\n')\n",
    "                f.write('score: ' + f'{label.score}\\n')\n",
    "                f.write('topicality: ' + f'{label.topicality}\\n\\n')\n",
    "    except StopIteration:\n",
    "        print('The iteration was stopped because there were empty files that have been removed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986a8e0-815b-430c-becd-c4c108d4f9b7",
   "metadata": {},
   "source": [
    "## 'labeltypes' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3191c-9e17-427c-958e-0f45e6103201",
   "metadata": {},
   "source": [
    "- Groups the descriptions of the labels of each image into a line of the file 'labels.txt' per image\n",
    "- Correction: include '| tr -d '\\r' |' in the pipeline to remove the carriage return character. This character causes errors in the format of the file 'labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5da17-bb3d-42b6-9635-6b4bc1303447",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cc251-47d8-44ba-a5cb-9e338c7417e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeltypes () {\n",
    "\n",
    "rm -f images/labels.txt\n",
    "\n",
    "last=$( cat images/images_index.txt | wc -l )\n",
    "\n",
    "for i in $(eval echo {1..$last});\n",
    "do    \n",
    "    sed -n \"${i}p\" images/images_index.txt > z\n",
    "    folder=$(cut -d'|' -f1 z | sed 's/fl://')\n",
    "    n=$(cut -d'|' -f2 z | sed 's/t://')\n",
    "    id=$(cut -d'|' -f3 z | sed 's/id://')\n",
    "    date=$(cut -d'|' -f4 z | sed 's/d://')\n",
    "    username=$(cut -d'|' -f5 z | sed 's/u://')\n",
    "\n",
    "    echo \"---- labeltypes $i / $last ---\"\n",
    "\n",
    "# Google Cloud Vision Labels in the format obtained from the original 'googlelabels' function (JSON format)\n",
    "#    grep '\"description\":' images/google_cloud/labels/\"$folder\"/\"$n\".txt | cut -d':' -f2 | tr -d '\"' | sed -e 's/^[ ]*//' | tr '\\n' ' ' | tr -d '\\r' | sed 's/, $//' | tr ' ' '_' | sed 's/,_/,/g' | tr -d \"'\" | tr '[A-Z]' '[a-z]' | sed \"s/^/fl:$folder|t:$n|id:$id|d:$date|u:$username|l:/\" >> images/labels.txt\n",
    "\n",
    "# Google Cloud Vision Labels in the format obtained from the Python version of the 'googlelabels' function\n",
    "    grep 'description:' images/google_cloud/labels/\"$folder\"/\"$n\".txt | cut -d':' -f2 | tr -d '\"' | sed -e 's/^[ ]*//' | tr '\\n' ', ' | tr -d '\\r' | sed 's/,$//' | tr ' ' '_' | sed 's/,_/,/g' | tr -d \"'\" | tr '[A-Z]' '[a-z]' | sed \"s/^/fl:$folder|t:$n|id:$id|d:$date|u:$username|l:/\" >> images/labels.txt\n",
    "    echo >> images/labels.txt\n",
    "done\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5183c2-b1b6-445c-bb83-2b4c4beb38ed",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe5415-9eaf-4fbf-9f7d-c8e40280c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['wsl', './labeltypes.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f857fbf0-f896-4715-a4d1-4204c5a88bdc",
   "metadata": {},
   "source": [
    "## 'toplabels' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44740365-7f8e-4600-a352-dc4cd53c77f4",
   "metadata": {},
   "source": [
    "- Creates a list of the most frequent labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548be4e0-c11a-49d4-ba7e-757c8c1cee62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425acab-c680-483e-8228-3c9a9df27b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toplabels () {\n",
    "\n",
    "cut -d'|' -f6 images/labels.txt | sed 's/l://' | tr ',' '\\n' | sort | uniq -c | sort -nr | sed 's/^[ ]*//' | grep '[a-z]' | head -1000 | cut -d' ' -f2- | nl -nrz | sed 's/^/v/' | tr '\\t' ' ' > images/selectedwords\n",
    "\n",
    "cp images/selectedwords images/var_index.txt\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ef351-e0c7-463a-bb1b-1205f953d009",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ffa894-2d64-43d3-8fcc-920210e76034",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['wsl', './toplabels.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b7aad-29e3-4703-b696-81ac135f4cc4",
   "metadata": {},
   "source": [
    "## 'sas' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d2be5-fbd8-4440-a740-5775ae646772",
   "metadata": {},
   "source": [
    "- Creates data to be processed in SAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b60267-d652-403d-9c90-0c0c69a38335",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f939f-77d8-4f01-ab1a-43f236ce4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sas () {\n",
    "\n",
    "mkdir -p images/sas\n",
    "\n",
    "rm -f images/columns\n",
    "\n",
    "cut -d'|' -f3,6 images/labels.txt > a\n",
    "\n",
    "while read n word \n",
    "do\n",
    "  echo \"--- $n ---\"\n",
    "  rg -w $word a | cut -d'|' -f1 | sed -e 's/id://' -e \"s/$/ \"$n\" 1/\" >> images/columns \n",
    "done < images/selectedwords\n",
    "\n",
    "sort images/columns | uniq > a ; mv a images/columns  # to avoid words whose accents were stripped to be duplicated in the same text ; SAS can't handle that\n",
    "\n",
    "#cut -d' ' -f2 tweets/selectedwords | gwc -L \n",
    "#head -1 columns | cut -d' ' -f1 | gwc -L\n",
    "\n",
    "cp images/columns images/sas/data.txt\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66324123-2296-4c6c-ab83-b00daf6809c1",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cee44-d24b-475b-97d5-3851b0a63834",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['wsl', './sas.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eddde9-5b57-4d55-a1d3-be896e994da3",
   "metadata": {},
   "source": [
    "## 'datamatrix' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eeb076-2ac3-4669-9e63-227799c6f272",
   "metadata": {},
   "source": [
    "- Creates a piece of information called datamatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512db31-61ef-40cf-a1b5-9fe58e1b7347",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef3a93-08b1-4a2e-9270-a25fd7853ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamatrix () {\n",
    "\n",
    "mkdir -p images/temp\n",
    "\n",
    "rm -f images/temp/*\n",
    "\n",
    "cut -d' ' -f1 images/columns | uniq | sort > files\n",
    "\n",
    "while read n word \n",
    "do\n",
    "  echo \"--- $n ---\"\n",
    "  rg -w $n images/columns | sort -t' ' -k1,1 > a\n",
    "  echo \"$n\" > images/temp/$n\n",
    "  join -a 1 -1 1 -2 1 -e 0 files a | sed \"s/$/ $n 0/\" | cut -d' ' -f3 >> images/temp/$n\n",
    "done < images/selectedwords\n",
    "\n",
    "echo \"--- images/data.csv ...---\"\n",
    "\n",
    "awk '\n",
    "        FNR==1 { col++ }\n",
    "        FNR>max { max=FNR }\n",
    "        { l[FNR,col]=$0 }\n",
    "        END {\n",
    "                for (i=1;i<=max;i++) {\n",
    "                        for (j=1;j<=col;j++) {\n",
    "                                printf \"%-50s\",l[i,j]\n",
    "                        }\n",
    "                        print \"\"\n",
    "                }\n",
    "        }\n",
    "' images/temp/* > u\n",
    "tr -s ' ' < u | tr ' ' ',' | sed 's/,$//' > images/data.csv\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae37742-c219-48cd-a883-e552db68edad",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3b006-2a28-41ee-bb6d-0a2f74cef6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['wsl', './datamatrix.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30839b24-4619-4e04-9bc5-51651bbbdc11",
   "metadata": {},
   "source": [
    "## 'correlationmatrix' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42a896-454f-4877-969b-17117ffc14aa",
   "metadata": {},
   "source": [
    "- Calculates a correlation matrix from 'images/data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a535594-04b5-4b72-ae14-508219f1f791",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d0aee-8de8-4590-9372-27f9122d7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationmatrix () {\n",
    "\n",
    "echo \"--- python correlation ... ---\"\n",
    "\n",
    "sed 's;data.csv;images/data.csv;' corr.py > p\n",
    "python3 p > images/correlation\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd97757-687d-45df-90f0-b5ae64c2e6a5",
   "metadata": {},
   "source": [
    "### Executable from this notebook\n",
    "Note: If 'data.csv' is large, the execution of the following cell may be suspended to prevent the Python kernel from crashing. Instead, you can run the programme as 'corr.py' over Python over Ubuntu over Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81a791-e07e-4b67-9c4b-015f490a84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.geeksforgeeks.org/create-a-correlation-matrix-using-python/\n",
    "\n",
    "# Create dataframe from file\n",
    "dataframe = pd.read_csv('images/data.csv')\n",
    "\n",
    "# Show dataframe\n",
    "#print(dataframe)\n",
    "\n",
    "# Use the corr() method on dataframe to create a correlation matrix\n",
    "matrix = dataframe.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "#print('The Correlation Matrix is: ')\n",
    "#print(matrix)\n",
    "\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 8,\n",
    "                       'display.width', 20000,\n",
    "                       ):\n",
    "    with open('images/correlation', 'w', encoding = 'utf8') as correlation:\n",
    "        correlation.write(str(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e25c1d-d4db-431f-9aa7-428b82d2cafa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Using Python over Ubuntu over Windows (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e104a6f-4018-4fe2-a21b-a6a60c69f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyamrog@RogLet-ASUS:~$ sudo apt update && sudo apt upgrade -y\n",
    "[sudo] password for eyamrog:\n",
    "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
    "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
    "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
    "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
    "Reading package lists... Done\n",
    "Building dependency tree... Done\n",
    "Reading state information... Done\n",
    "All packages are up to date.\n",
    "Reading package lists... Done\n",
    "Building dependency tree... Done\n",
    "Reading state information... Done\n",
    "Calculating upgrade... Done\n",
    "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
    "eyamrog@RogLet-ASUS:~$ cd environments/my_env\n",
    "eyamrog@RogLet-ASUS:~/environments/my_env$ source ./bin/activate\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ pip freeze\n",
    "aiohttp==3.8.5\n",
    "aiosignal==1.3.1\n",
    "asttokens==2.2.1\n",
    "async-timeout==4.0.3\n",
    "attrs==23.1.0\n",
    "backcall==0.2.0\n",
    "certifi==2023.7.22\n",
    "charset-normalizer==3.2.0\n",
    "click==8.1.6\n",
    "decorator==5.1.1\n",
    "executing==1.2.0\n",
    "frozenlist==1.4.0\n",
    "idna==3.4\n",
    "ipython==8.14.0\n",
    "jedi==0.19.0\n",
    "joblib==1.3.2\n",
    "matplotlib-inline==0.1.6\n",
    "multidict==6.0.4\n",
    "nltk==3.8.1\n",
    "openai==0.27.8\n",
    "parso==0.8.3\n",
    "pexpect==4.8.0\n",
    "pickleshare==0.7.5\n",
    "prompt-toolkit==3.0.39\n",
    "ptyprocess==0.7.0\n",
    "pure-eval==0.2.2\n",
    "Pygments==2.16.1\n",
    "regex==2023.8.8\n",
    "requests==2.31.0\n",
    "six==1.16.0\n",
    "stack-data==0.6.2\n",
    "textblob==0.17.1\n",
    "tqdm==4.66.1\n",
    "traitlets==5.9.0\n",
    "urllib3==2.0.4\n",
    "wcwidth==0.2.6\n",
    "yarl==1.9.2\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ pip install pandas\n",
    "Collecting pandas\n",
    "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
    "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 27.3 MB/s eta 0:00:00\n",
    "Collecting python-dateutil>=2.8.2\n",
    "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
    "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 KB 10.3 MB/s eta 0:00:00\n",
    "Collecting pytz>=2020.1\n",
    "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
    "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 502.5/502.5 KB 19.0 MB/s eta 0:00:00\n",
    "Collecting tzdata>=2022.1\n",
    "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
    "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.8/341.8 KB 18.0 MB/s eta 0:00:00\n",
    "Collecting numpy>=1.22.4\n",
    "  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
    "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 32.5 MB/s eta 0:00:00\n",
    "Requirement already satisfied: six>=1.5 in ./lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
    "Installing collected packages: pytz, tzdata, python-dateutil, numpy, pandas\n",
    "Successfully installed numpy-1.26.0 pandas-2.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 tzdata-2023.3\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ pip freeze | grep pandas\n",
    "pandas==2.1.1\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ cp /mnt/c/Users/eyamr/Downloads/data.csv .\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ cp /mnt/c/Users/eyamr/Downloads/corr.py .\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ more corr.py\n",
    "# Reference: https://www.geeksforgeeks.org/create-a-correlation-matrix-using-python/\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create dataframe from file\n",
    "dataframe = pd.read_csv('data.csv')\n",
    "\n",
    "# Show dataframe\n",
    "#print(dataframe)\n",
    "\n",
    "# Use the corr() method on dataframe to create a correlation matrix\n",
    "matrix = dataframe.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "#print('The Correlation Matrix is: ')\n",
    "#print(matrix)\n",
    "\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 8,\n",
    "                       'display.width', 20000,\n",
    "                       ):\n",
    "    with open('correlation', 'w', encoding = 'utf8') as correlation:\n",
    "        correlation.write(str(matrix))\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ python corr.py\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ ls -la\n",
    "total 35676\n",
    "drwxr-xr-x 8 eyamrog eyamrog    32768 Oct  7 10:00 .\n",
    "drwxr-xr-x 3 eyamrog eyamrog     4096 Oct  3 11:25 ..\n",
    "drwxr-xr-x 2 eyamrog eyamrog     4096 Oct  7 09:23 bin\n",
    "-rwxr-xr-x 1 eyamrog eyamrog      718 Oct  7 09:58 corr.py\n",
    "-rw-r--r-- 1 eyamrog eyamrog 12017004 Oct  7 10:00 correlation\n",
    "-rwxr-xr-x 1 eyamrog eyamrog 24324000 Oct  7 09:26 data.csv\n",
    "-rw-r--r-- 1 eyamrog eyamrog      250 Oct  4 16:33 files\n",
    "drwxr-xr-x 2 eyamrog eyamrog    32768 Oct  4 16:26 images\n",
    "drwxr-xr-x 2 eyamrog eyamrog     4096 Aug 17 13:28 include\n",
    "drwxr-xr-x 2 eyamrog eyamrog    69632 Oct  4 16:33 labels\n",
    "-rw-r--r-- 1 eyamrog eyamrog     6911 Oct  4 16:37 labels.zip\n",
    "drwxr-xr-x 3 eyamrog eyamrog     4096 Aug 17 13:28 lib\n",
    "lrwxrwxrwx 1 eyamrog eyamrog        3 Aug 17 13:28 lib64 -> lib\n",
    "-rw-r--r-- 1 eyamrog eyamrog       71 Aug 17 13:28 pyvenv.cfg\n",
    "drwxr-xr-x 3 eyamrog eyamrog     4096 Aug 20 10:50 share\n",
    "-rwxr-xr-x 1 eyamrog eyamrog      225 Oct  3 12:43 vision.sh\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ cp correlation /mnt/c/Users/eyamr/Downloads/\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ deactivate\n",
    "eyamrog@RogLet-ASUS:~/environments/my_env$ logout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9bf9c-6aea-408c-8e53-573c881e253c",
   "metadata": {},
   "source": [
    "## 'formats' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7453c7f-7ef9-4542-a3c7-e3590c613d8b",
   "metadata": {},
   "source": [
    "- It is not possible to determine the purpose of this function. We are placing it on hold until further clarification is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30cc0a5-132e-4add-996a-ae876350279c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02bc06-aa5b-4613-b94d-042ebade9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "formats () {\n",
    "\n",
    "nlines=$( cat tweets/emoji.txt | wc -l | tr -dc '[0-9]' )\n",
    "\n",
    "tail +2 images/correlation | tr -s ' ' | sed 's/^/CORR /' > bottom\n",
    "head -1 images/correlation | tr -s ' ' | sed 's/^[ ]*//' | sed \"s/\\(v......\\)/$nlines/g\" | sed 's/^/N . /' > n\n",
    "\n",
    "sed 's;data.csv;images/data.csv;' std.py > p\n",
    "python3 p > s \n",
    "tr -s ' ' < s | cut -d' ' -f2 | grep -v 'float' | tr '\\n' ' ' | sed 's/^/STD\t . /' > std \n",
    "echo >> std\n",
    "\n",
    "sed 's;data.csv;images/data.csv;' mean.py > p\n",
    "python3 p > m \n",
    "tr -s ' ' < m | cut -d' ' -f2 | grep -v 'float' | tr '\\n' ' ' | sed 's/^/MEAN . /' > mean\n",
    "echo >> mean\n",
    "\n",
    "cat mean std n bottom > images/sas/corr.txt\n",
    "\n",
    "echo \"PROC FORMAT library=work ;\n",
    "  VALUE  \\$lexlabels\" > images/sas/word_labels_format.sas\n",
    "tr '\\t' ' ' < images/selectedwords | sed 's/\\(.*\\) \\(.*\\)/\"\\1\" = \"\\2\"/' | sed -e 's/&/and/g' -e 's/%/pc/g' >> images/sas/word_labels_format.sas\n",
    "echo \";\n",
    "run;\n",
    "quit;\" >> images/sas/word_labels_format.sas\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54cc81-d0c1-42ec-bdc6-a062de624ff6",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ddbd62-6c95-4d09-9080-536a59507a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdfcd11c-084f-430c-9d05-29e64a61634c",
   "metadata": {},
   "source": [
    "## 'examples' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848cb33-6c6a-427f-8421-72001fe5888d",
   "metadata": {},
   "source": [
    "- It is not possible to determine the purpose of this function. We are placing it on hold until further clarification is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bd67b-8802-457d-92dd-7dee95f32b57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a631dc-0c2a-4a95-9b10-f6b96017c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples () {\n",
    "\n",
    "mkdir -p images/examples\n",
    "rm -f images/examples/*\n",
    "\n",
    "html2text -nobs images/sas/output_group\"$group\"_images/loadtable.html > a\n",
    "\n",
    "rm -f x??\n",
    "split -p'=====' a\n",
    "ls x?? > files\n",
    "\n",
    "while read file\n",
    "do\n",
    "      pole=$( grep '^Factor ' $file | cut -d' ' -f2,3 | sed -e 's/^/f/' -e 's/ //g' )\n",
    "      sed 's/^[ ]*//' $file | grep '^[0-9]' | tr -dc '[:alpha:][:punct:][0-9]\\n ' | sed 's/^/~/' | tr  '[:space:]()' ' ' | tr -s ' ' |  tr '~' '\\n' | cut -d' ' -f2 | grep -v '^$' | sed \"s/^/$pole /\" \n",
    "done < files > images/examples/factors\n",
    "\n",
    "\n",
    "rm -f x??\n",
    "\n",
    "head -1 images/sas/output_group\"$group\"_images/group4_images_scores.tsv | tr -d '\\r' | tr '\\t' '\\n' > vars\n",
    "    \n",
    "last=$( cut -d' ' -f1 images/examples/factors | tr -dc '[0-9\\n]' | sort -nr | head -1 )\n",
    "    \n",
    "for i in $(eval echo {1..$last});\n",
    "do\n",
    "      column=$( echo \" $i + 1 \" | bc ) \n",
    "      cut -f1,\"$column\" images/sas/output_group4_images/group4_images_scores_only.tsv  | tail +2 > a\n",
    "\n",
    "      for pole in pos neg\n",
    "      do\n",
    "        echo \"--- \"f\"$i\"\"$pole\"\" ---\" \n",
    "\n",
    "        if [ \"$pole\" == pos ] ; then\n",
    "           sort -nr -k2,2 a | grep -v '\\-' | tr '\\t' ' ' | grep -v ' 0' | head -20 | nl -nrz > files\n",
    "        else\n",
    "           sort -n -k2,2 a | grep '\\-' | tr '\\t' ' ' | grep -v ' 0' | grep -v '\t0' | head -20 | nl -nrz > files\n",
    "        fi\n",
    "\n",
    "        grep f\"$i\"\"$pole\" images/examples/factors | sort -t' ' -k2,2 | cut -d' ' -f2 | sort > factor_words\n",
    "        \n",
    "        while read n file score\n",
    "        do\n",
    "\n",
    "          grep -m1 $file images/sas/output_group4_images/group4_images_scores.tsv | tr -d '\\r' | tr '\\t' '\\n' > scores\n",
    "          paste vars scores | tr '\\t' ' ' | grep '^v' | grep -v ' 0$' | cut -d' ' -f1 | sort > vars_text\n",
    "          join vars_text images/selectedwords | cut -d' ' -f2 | sort > vars_text_codes\n",
    "          username=$( grep -w $file user_index.txt | cut -d' ' -f2 )\n",
    "          picture=$( grep -w $file images/images_index.txt | cut -d'|' -f2,7 | tr ':|' ' ' | cut -d' ' -f2,4 | sed 's;\\(.*\\) \\(.*\\);\\1.\\2;' )\n",
    "          folder=$( grep -w $file images/images_index.txt | cut -d'|' -f1 | tr ':|' ' ' | cut -d' ' -f2  )\n",
    "          url=$( grep -m1 -B5 $file tweets/jq.txt | grep '\"url\"'  | cut -d':' -f2- | tr -d '\",' | sed 's/^[ ]*//' )\n",
    "          extension=$( echo $picture | cut -d'.' -f2 )\n",
    "          cp images/images/$folder/$picture images/examples/image_f\"$i\"\"$pole\"_x`\"$n\".\"$extension\"\n",
    "\n",
    "          echo \"---------------\" \n",
    "\n",
    "          echo \"# $n\" \n",
    "          echo \"score = $score\"  \n",
    "          echo \"url: $url\"\n",
    "          echo\n",
    "\n",
    "          grep -w $file images/labels.txt | tr '|' '\\n' | sed 's/l:/~/' | tr '~' '\\n'    \n",
    "\n",
    "          echo\n",
    "          echo \"Lemmas in this picture that loaded on the factor:\"\n",
    "          echo\n",
    "\n",
    "          join vars_text_codes factor_words > ll\n",
    "          tr '\\n' ',' < ll | sed 's/,/, /g' | sed 's/, $//' > images/examples/lemmas_f\"$i\"_\"$pole\"_\"$n\".txt\n",
    "          cat ll\n",
    "\n",
    "          echo \n",
    "\n",
    "        done < files > images/examples/examples_f\"$i\"_\"$pole\".txt\n",
    "\n",
    "      done\n",
    "\n",
    "done\n",
    "\n",
    "    #rm -f vars factor_words scores vars_text vars_text_codes\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d53ca2-8c00-4235-95ee-51f4951fb974",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc490f0-4a66-4790-b770-0c42e91f3777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
