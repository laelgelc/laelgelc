{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"http://corpuslg.org/lael_english/wp-content/uploads/2020/04/lael_50_years_narrow_white.png.400px_300dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Images function set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f45250f-188e-4d39-91ed-635f368b0e0d",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f48b2be7-329a-40ec-818c-e78e99371bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bcd50d-04ff-4428-af11-4e576a37e7dd",
   "metadata": {},
   "source": [
    "## Preamble (Do not execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3619e9-f7d1-4a0b-bb1c-c5c8b9fe7565",
   "metadata": {},
   "source": [
    "- Group number definition\n",
    "- Selects the syntax of the the commands 'shuf' and 'sed' for Mac or Linux platforms\n",
    "- The variables 'myshuf' and 'mysed' are not used in the programme\n",
    "- Decision: comment it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7e0af-51f7-4240-8007-d1fe8f137838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter your group number\n",
    "#group=4\n",
    "\n",
    "#enter the label for your system, mac or linux\n",
    "#mysystem=mac\n",
    "#mysystem=linux\n",
    "\n",
    "#  if [ \"$mysystem\" == mac ]\n",
    "#    then\n",
    "#    myshuf=gshuf\n",
    "#    mygsed=gsed\n",
    "#  else\n",
    "#    myshuf=shuf\n",
    "#    mygsed=sed\n",
    "#  fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0292236-2255-412d-a679-09742685cb26",
   "metadata": {},
   "source": [
    "## 'presample' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0138bce-308d-4681-aee8-655e7aea3074",
   "metadata": {},
   "source": [
    "- Processes 'tweets/scraped.txt' into 'images/presample.txt'\n",
    "- Correction to create the folder 'images' for the first tine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143408f-9e27-4e02-8ca5-c7dbd15e05ce",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01855a-1bfd-493f-85d5-ce70e5891b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "presample () {\n",
    "\n",
    "mkdir -p images\n",
    "\n",
    "grep fullUrl tweets/scraped.txt | cut -f2- | nl | sed 's/^[ ]*//' > images/presample.txt\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad1c55-684c-4827-ad80-175716b71928",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9776ac-9b61-451d-8e5b-5b4d328d339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['wsl', './presample.sh'], returncode=0, stdout=b'\\x1b[H\\x1b[2J\\x1b[3J', stderr=b'')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['wsl', './presample.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b865a3e-b03d-4117-8138-3129d0daef08",
   "metadata": {},
   "source": [
    "## 'collecturls' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549cf86b-2c6b-45c9-9de3-444d3c9b9ec4",
   "metadata": {},
   "source": [
    "- Processes 'images/presample.txt' into 'images/images_index.txt'\n",
    "- Defines 13 image batches with 1000 images in each batch\n",
    "- Creates one folder for each batch in 'images/images'\n",
    "- The commands 'rg' and 'jq' are required\n",
    "- Correction to resolve folder naming conflict with 'grabimages' function\n",
    "    - from: 'sort z | uniq > folders'\n",
    "    - to: 'sort z | uniq | sed 's/fl://' > folders'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57c540-3ff5-42a1-80a5-bfe88a8b3f6e",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbeca2-f794-4f27-a922-63fe352005de",
   "metadata": {},
   "outputs": [],
   "source": [
    "getimagesurls () {\n",
    "\n",
    "last=$( cat images/presample.txt | wc -l | tr -dc '[0-9]' )\n",
    "\n",
    "#mkdir -p images\n",
    "\n",
    "rm -f images/urls.txt  ### WATCH THIS!\n",
    "\n",
    "for i in $(eval echo {1..$last});\n",
    "do\n",
    "        rg -m1 \"^\"$i\"\t\" images/presample.txt | jq '.' > z\n",
    "        file=$( grep -m1 'fullUrl' z | cut -d'\"' -f4  )\n",
    "        format=$( echo $file | tr '?&=' '|' | cut -d'|' -f3 )\n",
    "        id=$( grep -m1 'id\"' z | tr '~' ' ' | sed -e 's/^[ ]*//' -e 's/:/~/' | cut -d'~' -f2 | tr -dc '[0-9]' )\n",
    "        username=$( grep -m1 'username\"' z | tr '~' ' ' | sed -e 's/^[ ]*//' -e 's/:/~/' | cut -d'~' -f2 | sed -e 's/\"//' -e 's/^[ ]*//' -e 's/\",$//' | tr '[:upper:]' '[:lower:]' )\n",
    "        date=$( grep -m1 'date\"' z | tr '~' ' ' | sed -e 's/^[ ]*//' | cut -d'~' -f2 | cut -d'T' -f1 | tr -dc '[0-9-]' )\n",
    "\n",
    "        echo \"---- collecturls $i / $last ----\"\n",
    "\n",
    "        echo \"id:\"$id\"|d:$date|u:\"$username\"|i:$file|f:$format\" >> images/urls.txt\n",
    "done \n",
    "\n",
    "grep 'id:...................|' images/urls.txt | nl -nrz | sed 's/^/t:/' | tr '\\t' '|' > w\n",
    "\n",
    "for n in `seq -w 1 13`  # how many batches\n",
    "do\n",
    "  printf \"$n\\n%.0s\" {1..1000}  # how many lines in each batch\n",
    "done | sed 's/^/fl:/' > z\n",
    "\n",
    "paste z w | tr '\\t' '|' | grep 'id:' > images/images_index.txt\n",
    "\n",
    "#sort z | uniq > folders\n",
    "sort z | uniq | sed 's/fl://' > folders\n",
    "while read folder\n",
    "do\n",
    "    mkdir -p images/images/$folder\n",
    "done < folders\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa6a380-9deb-4cfb-bc8d-6add86fbb671",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4e4f6e-f2a7-450d-8fb5-89109b1d7ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['wsl', './getimagesurls.sh'], returncode=0, stdout=b'\\x1b[H\\x1b[2J\\x1b[3J---- collecturls 1 / 20 ----\\n---- collecturls 2 / 20 ----\\n---- collecturls 3 / 20 ----\\n---- collecturls 4 / 20 ----\\n---- collecturls 5 / 20 ----\\n---- collecturls 6 / 20 ----\\n---- collecturls 7 / 20 ----\\n---- collecturls 8 / 20 ----\\n---- collecturls 9 / 20 ----\\n---- collecturls 10 / 20 ----\\n---- collecturls 11 / 20 ----\\n---- collecturls 12 / 20 ----\\n---- collecturls 13 / 20 ----\\n---- collecturls 14 / 20 ----\\n---- collecturls 15 / 20 ----\\n---- collecturls 16 / 20 ----\\n---- collecturls 17 / 20 ----\\n---- collecturls 18 / 20 ----\\n---- collecturls 19 / 20 ----\\n---- collecturls 20 / 20 ----\\n', stderr=b'')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['wsl', './getimagesurls.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563469c-965c-4f22-b71f-dfc71d4d97fa",
   "metadata": {},
   "source": [
    "## 'grabimages' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dfd915-32b1-40d5-96de-cd3ece1c25b9",
   "metadata": {},
   "source": [
    "- Processes 'images/images_index.txt' into ''\n",
    "- The command 'curl' is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734261d5-172d-4718-98fc-cdee1442ee69",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ad421-84fc-4938-b089-c9b2916f8183",
   "metadata": {},
   "outputs": [],
   "source": [
    "grabimages () {\n",
    "\n",
    "last=$( cat images/images_index.txt | wc -l | tr -cd '[0-9]' )\n",
    "\n",
    "for i in $(eval echo {1..$last});\n",
    "do\n",
    "    sed -n \"$i\"p images/images_index.txt > z\n",
    "    folder=$( cut -d'|' -f1 z | sed 's/fl://' )\n",
    "    n=$( cut -d'|' -f2 z | sed 's/t://' )\n",
    "    id=$( cut -d'|' -f3 z | sed 's/id://' )\n",
    "    file=$( cut -d'|' -f6 z | sed 's/i://' )\n",
    "    ext=$( cut -d'|' -f7 z | sed 's/f://' )\n",
    "    \n",
    "    echo \"---- fetching image $n / $last ----\"\n",
    "    \n",
    "    curl -k \"$file\" > images/images/\"$folder\"/\"$n\".\"$ext\"\n",
    "done \n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8844d20-080a-4231-99fb-5efa7305283d",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6a3c60-a0dd-4444-9b07-1c6739db7d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['wsl', './grabimages.sh'], returncode=0, stdout=b'\\x1b[H\\x1b[2J\\x1b[3J---- fetching image 000001 / 20 ----\\n---- fetching image 000002 / 20 ----\\n---- fetching image 000003 / 20 ----\\n---- fetching image 000004 / 20 ----\\n---- fetching image 000005 / 20 ----\\n---- fetching image 000006 / 20 ----\\n---- fetching image 000007 / 20 ----\\n---- fetching image 000008 / 20 ----\\n---- fetching image 000009 / 20 ----\\n---- fetching image 000010 / 20 ----\\n---- fetching image 000011 / 20 ----\\n---- fetching image 000012 / 20 ----\\n---- fetching image 000013 / 20 ----\\n---- fetching image 000014 / 20 ----\\n---- fetching image 000015 / 20 ----\\n---- fetching image 000016 / 20 ----\\n---- fetching image 000017 / 20 ----\\n---- fetching image 000018 / 20 ----\\n---- fetching image 000019 / 20 ----\\n---- fetching image 000020 / 20 ----\\n', stderr=b'  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100 80693  100 80693    0     0   295k      0 --:--:-- --:--:-- --:--:--  298k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100 82431  100 82431    0     0   628k      0 --:--:-- --:--:-- --:--:--  633k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100 84675  100 84675    0     0   554k      0 --:--:-- --:--:-- --:--:--  558k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100 73261  100 73261    0     0   445k      0 --:--:-- --:--:-- --:--:--  452k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  439k  100  439k    0     0  2278k      0 --:--:-- --:--:-- --:--:-- 2287k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100 80616  100 80616    0     0   378k      0 --:--:-- --:--:-- --:--:--  378k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r 18  433k   18 81920    0     0   570k      0 --:--:-- --:--:-- --:--:--  571k\\r100  433k  100  433k    0     0  2085k      0 --:--:-- --:--:-- --:--:-- 2085k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  148k  100  148k    0     0   872k      0 --:--:-- --:--:-- --:--:--  875k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  255k  100  255k    0     0  1509k      0 --:--:-- --:--:-- --:--:-- 1511k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  303k  100  303k    0     0  1370k      0 --:--:-- --:--:-- --:--:-- 1372k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  154k  100  154k    0     0   934k      0 --:--:-- --:--:-- --:--:--  935k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100 79314  100 79314    0     0   456k      0 --:--:-- --:--:-- --:--:--  461k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  119k  100  119k    0     0   765k      0 --:--:-- --:--:-- --:--:--  769k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r 30  159k   30 49152    0     0   403k      0 --:--:-- --:--:-- --:--:--  403k\\r100  159k  100  159k    0     0   962k      0 --:--:-- --:--:-- --:--:--  962k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  469k  100  469k    0     0  2305k      0 --:--:-- --:--:-- --:--:-- 2313k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  7383  100  7383    0     0  64049      0 --:--:-- --:--:-- --:--:-- 64200\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100 94917  100 94917    0     0   623k      0 --:--:-- --:--:-- --:--:--  626k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  122k  100  122k    0     0   822k      0 --:--:-- --:--:-- --:--:--  825k\\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\r100  158k  100  158k    0     0   851k      0 --:--:-- --:--:-- --:--:--  847k\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['wsl', './grabimages.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e585608-98b2-4d9d-92dc-8b8b1cdcd9ad",
   "metadata": {},
   "source": [
    "## 'removedupes' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf83a74-d783-480f-92cf-7d6510a0dad5",
   "metadata": {},
   "source": [
    "- Removes duplicate images posted in the same message or in repeated messages by the same user (same message id)\n",
    "- The function was empirically tested by manually introducing a duplicate image-containing message in 'tweets/scraped.txt' and it works as expected. It returns the following error message that apparently does not harm its functionality\n",
    "    - './removedupes.sh: line 27: remove: No such file or directory\\ngrep: remove: No such file or directory\\nfind: paths must precede expression: `empty'\\n'\n",
    "- When there are no duplicates, the function ends with the following error message. This result is not harmful because it proves that there are no duplicates\n",
    "    - './removedupes.sh: line 27: remove: No such file or directory\\ngrep: remove: No such file or directory\\nfind: paths must precede expression: `empty'\\n'\n",
    "- Correction to avoid 'images/images_index.txt' to have all lines excluded in case thare are no duplicates and, thus, the 'remove' file is empty\n",
    "- Correction to avoid an error condition in case there are no duplicates and the file 'remove' is not generated\n",
    "- Correction from 'find images/images -type f empty -exec rm {} +' to 'find images/images -type f -empty -exec rm {} +'\n",
    "- Correction from 'cat i i f | sort | uniq -c | grep ' 2 ' | cut -c6- | grep -v '^$' | sed 's/^/t:/' > ionly' to 'cat i i f | sort | uniq -c | grep ' 2 ' | cut -c9- | grep -v '^$' | sed 's/^/t:/' > ionly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7643a02-a754-4c58-b745-891a35b65c89",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e209507-1085-4c86-b5cd-3cd054cf7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "removedupes () {\n",
    "\n",
    "# remove duplicate images posted in the same message or in repeated messages by the same user (same message id)\n",
    "    \n",
    "cut -d'|' -f3 images/images_index.txt | sed 's/id://' | sort | uniq -c | grep -v ' 1 ' | nl | sed 's/^[ ]*//' | tr '\\t' ' ' | tr -s ' ' > d\n",
    "\n",
    "rm -f remove\n",
    "\n",
    "while read n maxhits id\n",
    "do\n",
    "    echo \"--- listing $n ---\"\n",
    "    grep -m$maxhits $id images/images_index.txt | cut -d'|' -f6 | sort | uniq -d | sed 's/i://' > dupes\n",
    "    \n",
    "    while read dupe\n",
    "    do\n",
    "        grep $dupe images/images_index.txt | tail +2 | cut -d'|' -f2\n",
    "    done < dupes >> remove\n",
    "done < d \n",
    "\n",
    "# remove duplicate image files\n",
    "#while read dupe\n",
    "#do\n",
    "#    pretty=$( echo $dupe | sed 's/t://' )\n",
    "#    folder=$( grep $dupe images/images_index.txt | cut -d'|' -f1 | sed 's/fl://' )\n",
    "#    ext=$( grep $dupe images/images_index.txt | cut -d'|' -f7 | sed 's/f://' )\n",
    "#    rm -f images/images/\"$folder\"/\"$pretty\".\"$ext\"\n",
    "#    echo \"--- removing images/images/\"$folder\"/\"$pretty\".\"$ext\" ---\"\n",
    "#done < remove\n",
    "if [[ -s remove ]]; then\n",
    "    while read dupe\n",
    "    do\n",
    "        pretty=$( echo $dupe | sed 's/t://' )\n",
    "        folder=$( grep $dupe images/images_index.txt | cut -d'|' -f1 | sed 's/fl://' )\n",
    "        ext=$( grep $dupe images/images_index.txt | cut -d'|' -f7 | sed 's/f://' )\n",
    "        rm -f images/images/\"$folder\"/\"$pretty\".\"$ext\"\n",
    "        echo \"--- removing images/images/\"$folder\"/\"$pretty\".\"$ext\" ---\"\n",
    "    done < remove\n",
    "fi\n",
    "\n",
    "# remove dupes from index\n",
    "#grep -vf remove images/images_index.txt > z ; mv z images/images_index.txt\n",
    "if [[ -s remove ]]; then\n",
    "    grep -vf remove images/images_index.txt > z ; mv z images/images_index.txt\n",
    "fi\n",
    "\n",
    "# remove dupes from index again, for some reason some still remain\n",
    "cut -d'|' -f2  images/images_index.txt | cut -d':' -f2 > i\n",
    "find images/images -type f | cut -d'/' -f4 | cut -d'.' -f1 > f\n",
    "cat i i f | sort | uniq -c | grep ' 2 ' | cut -c9- | grep -v '^$' | sed 's/^/t:/' > ionly\n",
    "grep -vf ionly images/images_index.txt > b ; mv b images/images_index.txt\n",
    "\n",
    "# remove empty image files\n",
    "find images/images -type f -empty -exec rm {} +\n",
    "\n",
    "# remove empty image files from index\n",
    "cut -d'|' -f2  images/images_index.txt | cut -d':' -f2 > i\n",
    "find images/images -type f | cut -d'/' -f4 | cut -d'.' -f1 > f\n",
    "cat i i f | sort | uniq -c | grep ' 2 ' | cut -c9- | grep -v '^$' | sed 's/^/t:/' > ionly\n",
    "grep -vf ionly images/images_index.txt > b ; mv b images/images_index.txt\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4b08e-b98c-4a4f-928d-da3bdc2533e1",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8414bc00-b04e-4402-b3c9-acfe32e513b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['wsl', './removedupes.sh'], returncode=0, stdout=b'\\x1b[H\\x1b[2J\\x1b[3J', stderr=b'')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['wsl', './removedupes.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a6686-4bd0-4f3b-8781-cccd41de4c77",
   "metadata": {},
   "source": [
    "## 'uploadtobucket' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641d3fe-5a66-4007-bb82-5fe5d62a4116",
   "metadata": {},
   "source": [
    "- Copies the 'images/images' folder to the user's Google Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cc347-23f2-436a-8f81-1cbc545f5a73",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705087af-4a6b-427c-8de2-ad68cea4d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploadtobucket () {\n",
    "\n",
    "# google cloud gsutil account = tonyberber@gmail.com\n",
    "\n",
    "gcloud alpha storage cp -R images/images gs://socialmediaclassimages/group\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc709e3-4f0c-451b-bd45-6d998acbfb7a",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f809b-05c4-46ed-9def-d94d1f4502c2",
   "metadata": {},
   "source": [
    "#### Using Google Cloud SDK Shell (Do not execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728b0bc-80f1-4cec-a552-82cb3ccb3fca",
   "metadata": {},
   "source": [
    "- On your Desktop, click on 'Google Cloud SDK Shell'\n",
    "- On the terminal window execute the commands as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca86c1-71fd-468d-ba3f-9d57529fc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the folder where the 'images' folder is located\n",
    "C:\\Users\\eyamr\\AppData\\Local\\Google\\Cloud SDK>cd C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground\n",
    "C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground>dir\n",
    " Volume in drive C is OS\n",
    " Volume Serial Number is FA6F-4E60\n",
    "\n",
    " Directory of C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground\n",
    "\n",
    "20/09/2023  17:43    <DIR>          .\n",
    "19/09/2023  15:29    <DIR>          ..\n",
    "<omitted>\n",
    "20/09/2023  17:37    <DIR>          images\n",
    "<omitted>\n",
    "              24 File(s)         51.289 bytes\n",
    "               5 Dir(s)  134.018.973.696 bytes free\n",
    "\n",
    "# List the buckets\n",
    "C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground>gcloud storage ls\n",
    "gs://laelimages/\n",
    "\n",
    "# Run the following commad\n",
    "C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground>gcloud alpha storage cp -R images/images gs://laelimages\n",
    "Copying file://images\\images\\01\\000001.jpg to gs://laelimages/images/01/000001.jpg\n",
    "Copying file://images\\images\\01\\000002.jpg to gs://laelimages/images/01/000002.jpg\n",
    "  Completed files 2/2 | 159.3kiB/159.3kiB\n",
    "\n",
    "Average throughput: 6.0MiB/s\n",
    "\n",
    "C:\\Users\\eyamr\\OneDrive\\Documentos\\0-Technology\\Anaconda\\playground>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e5460-4a2e-4315-a204-b8d8cf672526",
   "metadata": {},
   "source": [
    "#### Using the 'google-cloud-storage' Python library\n",
    "Alternative 1: Completely equivalent to the Google Cloud SDK approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed692ca-55ef-47e4-9d2e-f675ca781b92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory .\\images\\images uploaded to laelimages/images successfully!\n"
     ]
    }
   ],
   "source": [
    "def upload_directory_to_bucket(bucket_name, source_directory, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            blob_path = os.path.join(destination_blob_name, os.path.relpath(local_path, source_directory)).replace('\\\\', '/')\n",
    "            blob = bucket.blob(blob_path)\n",
    "            blob.upload_from_filename(local_path)\n",
    "\n",
    "    print(f'Directory {source_directory} uploaded to {bucket_name}/{destination_blob_name} successfully!')\n",
    "\n",
    "end = False\n",
    "while end == False:\n",
    "    my_bucket = str(input('Enter your bucket name: '))\n",
    "    if my_bucket != '':\n",
    "        bucket_name = my_bucket\n",
    "        end = True\n",
    "        clear_output()\n",
    "\n",
    "source_directory = r'.\\images\\images'\n",
    "destination_blob_name = 'images'\n",
    "upload_directory_to_bucket(bucket_name, source_directory, destination_blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46be61-6ac2-486d-abec-e82f0fbc0f77",
   "metadata": {},
   "source": [
    "#### Using the 'google-cloud-storage' Python library (Do not execute)\n",
    "Alternative 2: Copying even empty subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5e154-3743-45d5-a189-7d338c0392a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_directory_to_bucket(bucket_name, source_directory, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            blob_path = os.path.join(destination_blob_name, os.path.relpath(local_path, source_directory)).replace('\\\\', '/')\n",
    "            blob = bucket.blob(blob_path)\n",
    "            blob.upload_from_filename(local_path)\n",
    "\n",
    "        for dir in dirs:\n",
    "            dir_path = os.path.join(destination_blob_name, os.path.relpath(os.path.join(root, dir), source_directory)).replace('\\\\', '/')\n",
    "            blob = bucket.blob(dir_path + '/')\n",
    "            blob.upload_from_string('')\n",
    "\n",
    "    print(f'Directory {source_directory} uploaded to {bucket_name}/{destination_blob_name} successfully!')\n",
    "\n",
    "end = False\n",
    "while end == False:\n",
    "    my_bucket = str(input('Enter your bucket name: '))\n",
    "    if my_bucket != '':\n",
    "        bucket_name = my_bucket\n",
    "        end = True\n",
    "        clear_output()\n",
    "\n",
    "source_directory = r'.\\images\\images'\n",
    "destination_blob_name = 'images'\n",
    "upload_directory_to_bucket(bucket_name, source_directory, destination_blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cbfce-704b-4e16-bce8-3ff9af1e134d",
   "metadata": {},
   "source": [
    "## 'googlelabels' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f88f6-dff7-4b07-a74e-d1543374af77",
   "metadata": {},
   "source": [
    "- Detects the labels of the images with Google Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83b477-aeef-41f2-995c-c5b58abe754e",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e9bb3-0dda-4b71-963b-e17e07f2305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "googlelabels () {\n",
    "\n",
    "# speed: 1 file per second\n",
    "\n",
    "while read folder\n",
    "do\n",
    "  mkdir -p images/google_cloud/labels/$folder\n",
    "  ### rm -f images/google_cloud/labels/$folder/*\n",
    "done < folders\n",
    "\n",
    "last=$( tail -1 images/images_index.txt | cut -d'|' -f2 | sed 's/t://'  )\n",
    "\n",
    "for i in $(eval echo {1..$last});\n",
    "do\n",
    "    sed -n \"$i\"p images/images_index.txt > z\n",
    "    folder=$( cut -d'|' -f1 z | sed 's/fl://' )\n",
    "    n=$( cut -d'|' -f2 z | sed 's/t://' )\n",
    "    id=$( cut -d'|' -f3 z | sed 's/id://' )\n",
    "    file=$( cut -d'|' -f6 z | sed 's/i://' )\n",
    "    ext=$( cut -d'|' -f7 z | sed 's/f://' )\n",
    "    \n",
    "    echo \"---- detect-labels $i / $last ----\"\n",
    "    \n",
    "    gcloud ml vision detect-labels --max-results=150  gs://socialmediaclassimages/group/\"$folder\"/\"$n\".\"$ext\" > images/google_cloud/labels/\"$folder\"/\"$n\".txt\n",
    "    \n",
    "done \n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d051d4-2312-4c42-834f-8299ecc4b1e5",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e99f3a-466f-4add-8f19-746bdc12abbb",
   "metadata": {},
   "source": [
    "#### Using the 'google-cloud-vision' Python library\n",
    "It is a Python code that is functionally equivalent to the original shell script (so it is a valid artefact) but it generates an output file format that may be incompatible with the subsequent shell scripts in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8399956e-ad28-41a7-9d9b-047e38c740a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- detect-labels 1 / 20 ----\n",
      "---- detect-labels 2 / 20 ----\n",
      "---- detect-labels 3 / 20 ----\n",
      "---- detect-labels 4 / 20 ----\n",
      "---- detect-labels 5 / 20 ----\n",
      "---- detect-labels 6 / 20 ----\n",
      "---- detect-labels 7 / 20 ----\n",
      "---- detect-labels 8 / 20 ----\n",
      "---- detect-labels 9 / 20 ----\n",
      "---- detect-labels 10 / 20 ----\n",
      "---- detect-labels 11 / 20 ----\n",
      "---- detect-labels 12 / 20 ----\n",
      "---- detect-labels 13 / 20 ----\n",
      "---- detect-labels 14 / 20 ----\n",
      "---- detect-labels 15 / 20 ----\n",
      "---- detect-labels 16 / 20 ----\n",
      "---- detect-labels 17 / 20 ----\n",
      "---- detect-labels 18 / 20 ----\n",
      "---- detect-labels 19 / 20 ----\n",
      "The iteration was stopped because there were empty files that have been removed.\n"
     ]
    }
   ],
   "source": [
    "def detect_labels(image_uri):\n",
    "    \"\"\"Detects labels in the image URL using the Google Cloud Vision API.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = image_uri\n",
    "    response = client.label_detection(image = image, max_results = 150)\n",
    "    if response.error.message:\n",
    "        raise Exception(f'Error: {response.error.message}')\n",
    "    return response.label_annotations\n",
    "\n",
    "with open('folders', 'r') as f:\n",
    "    for folder in f:\n",
    "        folder = folder.strip()\n",
    "        os.makedirs(f'images/google_cloud/labels/{folder}', exist_ok = True)\n",
    "        # os.system(f'rm -f images/google_cloud/labels/{folder}/*')\n",
    "\n",
    "last = subprocess.run(['wsl', 'tail', '-1', 'images/images_index.txt'], capture_output = True, text = True).stdout.strip().split('|')[1][2:]\n",
    "last = int(last)\n",
    "\n",
    "for i in range(1, last + 1):\n",
    "    try:\n",
    "        with open('images/images_index.txt', 'r') as f:\n",
    "            line = next(line for j, line in enumerate(f, start = 1) if j == i)\n",
    "            folder = line.split('|')[0][3:]\n",
    "            n = line.split('|')[1][2:]\n",
    "            id = line.split('|')[2][3:]\n",
    "            file = line.split('|')[5][2:]\n",
    "            ext = line.split('|')[6][2:5]\n",
    "\n",
    "        print(f\"---- detect-labels {i} / {last} ----\")\n",
    "\n",
    "        image_uri = f'gs://{bucket_name}/images/{folder}/{n}.{ext}'\n",
    "        labels = detect_labels(image_uri)\n",
    "        with open(f'images/google_cloud/labels/{folder}/{n}.txt', 'w') as f:\n",
    "            for label in labels:\n",
    "                f.write('description: ' + f'{label.description}\\n')\n",
    "                f.write('mid: ' + f'{label.mid}\\n')\n",
    "                f.write('score: ' + f'{label.score}\\n')\n",
    "                f.write('topicality: ' + f'{label.topicality}\\n\\n')\n",
    "    except StopIteration:\n",
    "        print('The iteration was stopped because there were empty files that have been removed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986a8e0-815b-430c-becd-c4c108d4f9b7",
   "metadata": {},
   "source": [
    "## 'labeltypes' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3191c-9e17-427c-958e-0f45e6103201",
   "metadata": {},
   "source": [
    "- Groups the descriptions of the labels of each image into a line of the file 'labels.txt' per image\n",
    "- Correction: include '| tr -d '\\r' |' in the pipeline to remove the carriage return character. This character causes errors in the format of the file 'labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5da17-bb3d-42b6-9635-6b4bc1303447",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cc251-47d8-44ba-a5cb-9e338c7417e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeltypes () {\n",
    "\n",
    "rm -f images/labels.txt\n",
    "\n",
    "last=$( cat images/images_index.txt | wc -l )\n",
    "\n",
    "for i in $(eval echo {1..$last});\n",
    "do    \n",
    "    sed -n \"${i}p\" images/images_index.txt > z\n",
    "    folder=$(cut -d'|' -f1 z | sed 's/fl://')\n",
    "    n=$(cut -d'|' -f2 z | sed 's/t://')\n",
    "    id=$(cut -d'|' -f3 z | sed 's/id://')\n",
    "    date=$(cut -d'|' -f4 z | sed 's/d://')\n",
    "    username=$(cut -d'|' -f5 z | sed 's/u://')\n",
    "\n",
    "    echo \"---- labeltypes $i / $last ---\"\n",
    "\n",
    "# Google Cloud Vision Labels in the format obtained from the original 'googlelabels' function (JSON format)\n",
    "#    grep '\"description\":' images/google_cloud/labels/\"$folder\"/\"$n\".txt | cut -d':' -f2 | tr -d '\"' | sed -e 's/^[ ]*//' | tr '\\n' ' ' | tr -d '\\r' | sed 's/, $//' | tr ' ' '_' | sed 's/,_/,/g' | tr -d \"'\" | tr '[A-Z]' '[a-z]' | sed \"s/^/fl:$folder|t:$n|id:$id|d:$date|u:$username|l:/\" >> images/labels.txt\n",
    "\n",
    "# Google Cloud Vision Labels in the format obtained from the Python version of the 'googlelabels' function\n",
    "    grep 'description:' images/google_cloud/labels/\"$folder\"/\"$n\".txt | cut -d':' -f2 | tr -d '\"' | sed -e 's/^[ ]*//' | tr '\\n' ', ' | tr -d '\\r' | sed 's/,$//' | tr ' ' '_' | sed 's/,_/,/g' | tr -d \"'\" | tr '[A-Z]' '[a-z]' | sed \"s/^/fl:$folder|t:$n|id:$id|d:$date|u:$username|l:/\" >> images/labels.txt\n",
    "    echo >> images/labels.txt\n",
    "done\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5183c2-b1b6-445c-bb83-2b4c4beb38ed",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cbe5415-9eaf-4fbf-9f7d-c8e40280c3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['wsl', './labeltypes.sh'], returncode=0, stdout=b'\\x1b[H\\x1b[2J\\x1b[3J---- labeltypes 1 / 19 ---\\n---- labeltypes 2 / 19 ---\\n---- labeltypes 3 / 19 ---\\n---- labeltypes 4 / 19 ---\\n---- labeltypes 5 / 19 ---\\n---- labeltypes 6 / 19 ---\\n---- labeltypes 7 / 19 ---\\n---- labeltypes 8 / 19 ---\\n---- labeltypes 9 / 19 ---\\n---- labeltypes 10 / 19 ---\\n---- labeltypes 11 / 19 ---\\n---- labeltypes 12 / 19 ---\\n---- labeltypes 13 / 19 ---\\n---- labeltypes 14 / 19 ---\\n---- labeltypes 15 / 19 ---\\n---- labeltypes 16 / 19 ---\\n---- labeltypes 17 / 19 ---\\n---- labeltypes 18 / 19 ---\\n---- labeltypes 19 / 19 ---\\n', stderr=b'')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['wsl', './labeltypes.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f857fbf0-f896-4715-a4d1-4204c5a88bdc",
   "metadata": {},
   "source": [
    "## 'toplabels' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44740365-7f8e-4600-a352-dc4cd53c77f4",
   "metadata": {},
   "source": [
    "- Creates a list of the most frequent labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548be4e0-c11a-49d4-ba7e-757c8c1cee62",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425acab-c680-483e-8228-3c9a9df27b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toplabels () {\n",
    "\n",
    "cut -d'|' -f6 images/labels.txt | sed 's/l://' | tr ',' '\\n' | sort | uniq -c | sort -nr | sed 's/^[ ]*//' | grep '[a-z]' | head -1000 | cut -d' ' -f2- | nl -nrz | sed 's/^/v/' | tr '\\t' ' ' > images/selectedwords\n",
    "\n",
    "cp images/selectedwords images/var_index.txt\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ef351-e0c7-463a-bb1b-1205f953d009",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ffa894-2d64-43d3-8fcc-920210e76034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['wsl', './toplabels.sh'], returncode=0, stdout=b'\\x1b[H\\x1b[2J\\x1b[3J', stderr=b'')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['wsl', './toplabels.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b7aad-29e3-4703-b696-81ac135f4cc4",
   "metadata": {},
   "source": [
    "## 'sas' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d2be5-fbd8-4440-a740-5775ae646772",
   "metadata": {},
   "source": [
    "- Creates data to be processed in SAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b60267-d652-403d-9c90-0c0c69a38335",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f939f-77d8-4f01-ab1a-43f236ce4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sas () {\n",
    "\n",
    "mkdir -p images/sas\n",
    "\n",
    "rm -f images/columns\n",
    "\n",
    "cut -d'|' -f3,6 images/labels.txt > a\n",
    "\n",
    "while read n word \n",
    "do\n",
    "  echo \"--- $n ---\"\n",
    "  rg -w $word a | cut -d'|' -f1 | sed -e 's/id://' -e \"s/$/ \"$n\" 1/\" >> images/columns \n",
    "done < images/selectedwords\n",
    "\n",
    "sort images/columns | uniq > a ; mv a images/columns  # to avoid words whose accents were stripped to be duplicated in the same text ; SAS can't handle that\n",
    "\n",
    "#cut -d' ' -f2 tweets/selectedwords | gwc -L \n",
    "#head -1 columns | cut -d' ' -f1 | gwc -L\n",
    "\n",
    "cp images/columns images/sas/data.txt\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66324123-2296-4c6c-ab83-b00daf6809c1",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff3cee44-d24b-475b-97d5-3851b0a63834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['wsl', './sas.sh'], returncode=0, stdout=b'\\x1b[H\\x1b[2J\\x1b[3J--- v000001 ---\\n--- v000002 ---\\n--- v000003 ---\\n--- v000004 ---\\n--- v000005 ---\\n--- v000006 ---\\n--- v000007 ---\\n--- v000008 ---\\n--- v000009 ---\\n--- v000010 ---\\n--- v000011 ---\\n--- v000012 ---\\n--- v000013 ---\\n--- v000014 ---\\n--- v000015 ---\\n--- v000016 ---\\n--- v000017 ---\\n--- v000018 ---\\n--- v000019 ---\\n--- v000020 ---\\n--- v000021 ---\\n--- v000022 ---\\n--- v000023 ---\\n--- v000024 ---\\n--- v000025 ---\\n--- v000026 ---\\n--- v000027 ---\\n--- v000028 ---\\n--- v000029 ---\\n--- v000030 ---\\n--- v000031 ---\\n--- v000032 ---\\n--- v000033 ---\\n--- v000034 ---\\n--- v000035 ---\\n--- v000036 ---\\n--- v000037 ---\\n--- v000038 ---\\n--- v000039 ---\\n--- v000040 ---\\n--- v000041 ---\\n--- v000042 ---\\n--- v000043 ---\\n--- v000044 ---\\n--- v000045 ---\\n--- v000046 ---\\n--- v000047 ---\\n--- v000048 ---\\n--- v000049 ---\\n--- v000050 ---\\n--- v000051 ---\\n--- v000052 ---\\n--- v000053 ---\\n--- v000054 ---\\n--- v000055 ---\\n--- v000056 ---\\n--- v000057 ---\\n--- v000058 ---\\n--- v000059 ---\\n--- v000060 ---\\n--- v000061 ---\\n--- v000062 ---\\n--- v000063 ---\\n--- v000064 ---\\n--- v000065 ---\\n--- v000066 ---\\n--- v000067 ---\\n--- v000068 ---\\n--- v000069 ---\\n--- v000070 ---\\n--- v000071 ---\\n--- v000072 ---\\n--- v000073 ---\\n--- v000074 ---\\n--- v000075 ---\\n--- v000076 ---\\n--- v000077 ---\\n--- v000078 ---\\n--- v000079 ---\\n--- v000080 ---\\n--- v000081 ---\\n--- v000082 ---\\n--- v000083 ---\\n--- v000084 ---\\n--- v000085 ---\\n--- v000086 ---\\n--- v000087 ---\\n--- v000088 ---\\n--- v000089 ---\\n--- v000090 ---\\n--- v000091 ---\\n--- v000092 ---\\n--- v000093 ---\\n--- v000094 ---\\n--- v000095 ---\\n--- v000096 ---\\n--- v000097 ---\\n--- v000098 ---\\n--- v000099 ---\\n--- v000100 ---\\n--- v000101 ---\\n--- v000102 ---\\n--- v000103 ---\\n--- v000104 ---\\n--- v000105 ---\\n--- v000106 ---\\n--- v000107 ---\\n--- v000108 ---\\n--- v000109 ---\\n--- v000110 ---\\n--- v000111 ---\\n--- v000112 ---\\n--- v000113 ---\\n--- v000114 ---\\n--- v000115 ---\\n--- v000116 ---\\n--- v000117 ---\\n--- v000118 ---\\n--- v000119 ---\\n--- v000120 ---\\n--- v000121 ---\\n--- v000122 ---\\n--- v000123 ---\\n--- v000124 ---\\n--- v000125 ---\\n--- v000126 ---\\n--- v000127 ---\\n--- v000128 ---\\n--- v000129 ---\\n--- v000130 ---\\n--- v000131 ---\\n--- v000132 ---\\n--- v000133 ---\\n--- v000134 ---\\n--- v000135 ---\\n--- v000136 ---\\n--- v000137 ---\\n--- v000138 ---\\n--- v000139 ---\\n--- v000140 ---\\n--- v000141 ---\\n--- v000142 ---\\n--- v000143 ---\\n--- v000144 ---\\n--- v000145 ---\\n--- v000146 ---\\n--- v000147 ---\\n--- v000148 ---\\n--- v000149 ---\\n--- v000150 ---\\n--- v000151 ---\\n--- v000152 ---\\n--- v000153 ---\\n--- v000154 ---\\n--- v000155 ---\\n--- v000156 ---\\n--- v000157 ---\\n--- v000158 ---\\n--- v000159 ---\\n--- v000160 ---\\n--- v000161 ---\\n--- v000162 ---\\n--- v000163 ---\\n--- v000164 ---\\n--- v000165 ---\\n--- v000166 ---\\n--- v000167 ---\\n--- v000168 ---\\n--- v000169 ---\\n--- v000170 ---\\n--- v000171 ---\\n--- v000172 ---\\n--- v000173 ---\\n--- v000174 ---\\n--- v000175 ---\\n--- v000176 ---\\n--- v000177 ---\\n--- v000178 ---\\n--- v000179 ---\\n--- v000180 ---\\n--- v000181 ---\\n--- v000182 ---\\n--- v000183 ---\\n--- v000184 ---\\n--- v000185 ---\\n--- v000186 ---\\n--- v000187 ---\\n--- v000188 ---\\n--- v000189 ---\\n--- v000190 ---\\n--- v000191 ---\\n--- v000192 ---\\n--- v000193 ---\\n--- v000194 ---\\n--- v000195 ---\\n--- v000196 ---\\n--- v000197 ---\\n--- v000198 ---\\n--- v000199 ---\\n--- v000200 ---\\n--- v000201 ---\\n--- v000202 ---\\n--- v000203 ---\\n', stderr=b'')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['wsl', './sas.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eddde9-5b57-4d55-a1d3-be896e994da3",
   "metadata": {},
   "source": [
    "## 'datamatrix' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eeb076-2ac3-4669-9e63-227799c6f272",
   "metadata": {},
   "source": [
    "- Creates a piece of information called datamatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512db31-61ef-40cf-a1b5-9fe58e1b7347",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef3a93-08b1-4a2e-9270-a25fd7853ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamatrix () {\n",
    "\n",
    "mkdir -p images/temp\n",
    "\n",
    "rm -f images/temp/*\n",
    "\n",
    "cut -d' ' -f1 images/columns | uniq | sort > files\n",
    "\n",
    "while read n word \n",
    "do\n",
    "  echo \"--- $n ---\"\n",
    "  rg -w $n images/columns | sort -t' ' -k1,1 > a\n",
    "  echo \"$n\" > images/temp/$n\n",
    "  join -a 1 -1 1 -2 1 -e 0 files a | sed \"s/$/ $n 0/\" | cut -d' ' -f3 >> images/temp/$n\n",
    "done < images/selectedwords\n",
    "\n",
    "echo \"--- images/data.csv ...---\"\n",
    "\n",
    "awk '\n",
    "        FNR==1 { col++ }\n",
    "        FNR>max { max=FNR }\n",
    "        { l[FNR,col]=$0 }\n",
    "        END {\n",
    "                for (i=1;i<=max;i++) {\n",
    "                        for (j=1;j<=col;j++) {\n",
    "                                printf \"%-50s\",l[i,j]\n",
    "                        }\n",
    "                        print \"\"\n",
    "                }\n",
    "        }\n",
    "' images/temp/* > u\n",
    "tr -s ' ' < u | tr ' ' ',' | sed 's/,$//' > images/data.csv\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae37742-c219-48cd-a883-e552db68edad",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df3b006-2a28-41ee-bb6d-0a2f74cef6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['wsl', './datamatrix.sh'], returncode=0, stdout=b'\\x1b[H\\x1b[2J\\x1b[3J--- v000001 ---\\n--- v000002 ---\\n--- v000003 ---\\n--- v000004 ---\\n--- v000005 ---\\n--- v000006 ---\\n--- v000007 ---\\n--- v000008 ---\\n--- v000009 ---\\n--- v000010 ---\\n--- v000011 ---\\n--- v000012 ---\\n--- v000013 ---\\n--- v000014 ---\\n--- v000015 ---\\n--- v000016 ---\\n--- v000017 ---\\n--- v000018 ---\\n--- v000019 ---\\n--- v000020 ---\\n--- v000021 ---\\n--- v000022 ---\\n--- v000023 ---\\n--- v000024 ---\\n--- v000025 ---\\n--- v000026 ---\\n--- v000027 ---\\n--- v000028 ---\\n--- v000029 ---\\n--- v000030 ---\\n--- v000031 ---\\n--- v000032 ---\\n--- v000033 ---\\n--- v000034 ---\\n--- v000035 ---\\n--- v000036 ---\\n--- v000037 ---\\n--- v000038 ---\\n--- v000039 ---\\n--- v000040 ---\\n--- v000041 ---\\n--- v000042 ---\\n--- v000043 ---\\n--- v000044 ---\\n--- v000045 ---\\n--- v000046 ---\\n--- v000047 ---\\n--- v000048 ---\\n--- v000049 ---\\n--- v000050 ---\\n--- v000051 ---\\n--- v000052 ---\\n--- v000053 ---\\n--- v000054 ---\\n--- v000055 ---\\n--- v000056 ---\\n--- v000057 ---\\n--- v000058 ---\\n--- v000059 ---\\n--- v000060 ---\\n--- v000061 ---\\n--- v000062 ---\\n--- v000063 ---\\n--- v000064 ---\\n--- v000065 ---\\n--- v000066 ---\\n--- v000067 ---\\n--- v000068 ---\\n--- v000069 ---\\n--- v000070 ---\\n--- v000071 ---\\n--- v000072 ---\\n--- v000073 ---\\n--- v000074 ---\\n--- v000075 ---\\n--- v000076 ---\\n--- v000077 ---\\n--- v000078 ---\\n--- v000079 ---\\n--- v000080 ---\\n--- v000081 ---\\n--- v000082 ---\\n--- v000083 ---\\n--- v000084 ---\\n--- v000085 ---\\n--- v000086 ---\\n--- v000087 ---\\n--- v000088 ---\\n--- v000089 ---\\n--- v000090 ---\\n--- v000091 ---\\n--- v000092 ---\\n--- v000093 ---\\n--- v000094 ---\\n--- v000095 ---\\n--- v000096 ---\\n--- v000097 ---\\n--- v000098 ---\\n--- v000099 ---\\n--- v000100 ---\\n--- v000101 ---\\n--- v000102 ---\\n--- v000103 ---\\n--- v000104 ---\\n--- v000105 ---\\n--- v000106 ---\\n--- v000107 ---\\n--- v000108 ---\\n--- v000109 ---\\n--- v000110 ---\\n--- v000111 ---\\n--- v000112 ---\\n--- v000113 ---\\n--- v000114 ---\\n--- v000115 ---\\n--- v000116 ---\\n--- v000117 ---\\n--- v000118 ---\\n--- v000119 ---\\n--- v000120 ---\\n--- v000121 ---\\n--- v000122 ---\\n--- v000123 ---\\n--- v000124 ---\\n--- v000125 ---\\n--- v000126 ---\\n--- v000127 ---\\n--- v000128 ---\\n--- v000129 ---\\n--- v000130 ---\\n--- v000131 ---\\n--- v000132 ---\\n--- v000133 ---\\n--- v000134 ---\\n--- v000135 ---\\n--- v000136 ---\\n--- v000137 ---\\n--- v000138 ---\\n--- v000139 ---\\n--- v000140 ---\\n--- v000141 ---\\n--- v000142 ---\\n--- v000143 ---\\n--- v000144 ---\\n--- v000145 ---\\n--- v000146 ---\\n--- v000147 ---\\n--- v000148 ---\\n--- v000149 ---\\n--- v000150 ---\\n--- v000151 ---\\n--- v000152 ---\\n--- v000153 ---\\n--- v000154 ---\\n--- v000155 ---\\n--- v000156 ---\\n--- v000157 ---\\n--- v000158 ---\\n--- v000159 ---\\n--- v000160 ---\\n--- v000161 ---\\n--- v000162 ---\\n--- v000163 ---\\n--- v000164 ---\\n--- v000165 ---\\n--- v000166 ---\\n--- v000167 ---\\n--- v000168 ---\\n--- v000169 ---\\n--- v000170 ---\\n--- v000171 ---\\n--- v000172 ---\\n--- v000173 ---\\n--- v000174 ---\\n--- v000175 ---\\n--- v000176 ---\\n--- v000177 ---\\n--- v000178 ---\\n--- v000179 ---\\n--- v000180 ---\\n--- v000181 ---\\n--- v000182 ---\\n--- v000183 ---\\n--- v000184 ---\\n--- v000185 ---\\n--- v000186 ---\\n--- v000187 ---\\n--- v000188 ---\\n--- v000189 ---\\n--- v000190 ---\\n--- v000191 ---\\n--- v000192 ---\\n--- v000193 ---\\n--- v000194 ---\\n--- v000195 ---\\n--- v000196 ---\\n--- v000197 ---\\n--- v000198 ---\\n--- v000199 ---\\n--- v000200 ---\\n--- v000201 ---\\n--- v000202 ---\\n--- v000203 ---\\n--- images/data.csv ...---\\n', stderr=b'')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['wsl', './datamatrix.sh'], capture_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30839b24-4619-4e04-9bc5-51651bbbdc11",
   "metadata": {},
   "source": [
    "## 'correlationmatrix' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42a896-454f-4877-969b-17117ffc14aa",
   "metadata": {},
   "source": [
    "- Calculates a correlation matrix from 'images/data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a535594-04b5-4b72-ae14-508219f1f791",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d0aee-8de8-4590-9372-27f9122d7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationmatrix () {\n",
    "\n",
    "echo \"--- python correlation ... ---\"\n",
    "\n",
    "sed 's;data.csv;images/data.csv;' corr.py > p\n",
    "python3 p > images/correlation\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd97757-687d-45df-90f0-b5ae64c2e6a5",
   "metadata": {},
   "source": [
    "### Executable from this notebook\n",
    "Note: If 'data.csv' is large, the execution of the following cell may be suspended to prevent the Python kernel from crashing. Instead, you can run the programme as 'corr.py' over Python over Ubuntu over Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d81a791-e07e-4b67-9c4b-015f490a84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.geeksforgeeks.org/create-a-correlation-matrix-using-python/\n",
    "\n",
    "# Create dataframe from file\n",
    "dataframe = pd.read_csv('images/data.csv')\n",
    "\n",
    "# Show dataframe\n",
    "#print(dataframe)\n",
    "\n",
    "# Use the corr() method on dataframe to create a correlation matrix\n",
    "matrix = dataframe.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "#print('The Correlation Matrix is: ')\n",
    "#print(matrix)\n",
    "\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 8,\n",
    "                       'display.width', 20000,\n",
    "                       ):\n",
    "    with open('images/correlation', 'w', encoding = 'utf8') as correlation:\n",
    "        correlation.write(str(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e25c1d-d4db-431f-9aa7-428b82d2cafa",
   "metadata": {},
   "source": [
    "#### Using Python over Ubuntu over Windows (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e104a6f-4018-4fe2-a21b-a6a60c69f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyamrog@RogLet-ASUS:~$ sudo apt update && sudo apt upgrade -y\n",
    "[sudo] password for eyamrog:\n",
    "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
    "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
    "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
    "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
    "Reading package lists... Done\n",
    "Building dependency tree... Done\n",
    "Reading state information... Done\n",
    "All packages are up to date.\n",
    "Reading package lists... Done\n",
    "Building dependency tree... Done\n",
    "Reading state information... Done\n",
    "Calculating upgrade... Done\n",
    "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
    "eyamrog@RogLet-ASUS:~$ cd environments/my_env\n",
    "eyamrog@RogLet-ASUS:~/environments/my_env$ source ./bin/activate\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ pip freeze\n",
    "aiohttp==3.8.5\n",
    "aiosignal==1.3.1\n",
    "asttokens==2.2.1\n",
    "async-timeout==4.0.3\n",
    "attrs==23.1.0\n",
    "backcall==0.2.0\n",
    "certifi==2023.7.22\n",
    "charset-normalizer==3.2.0\n",
    "click==8.1.6\n",
    "decorator==5.1.1\n",
    "executing==1.2.0\n",
    "frozenlist==1.4.0\n",
    "idna==3.4\n",
    "ipython==8.14.0\n",
    "jedi==0.19.0\n",
    "joblib==1.3.2\n",
    "matplotlib-inline==0.1.6\n",
    "multidict==6.0.4\n",
    "nltk==3.8.1\n",
    "openai==0.27.8\n",
    "parso==0.8.3\n",
    "pexpect==4.8.0\n",
    "pickleshare==0.7.5\n",
    "prompt-toolkit==3.0.39\n",
    "ptyprocess==0.7.0\n",
    "pure-eval==0.2.2\n",
    "Pygments==2.16.1\n",
    "regex==2023.8.8\n",
    "requests==2.31.0\n",
    "six==1.16.0\n",
    "stack-data==0.6.2\n",
    "textblob==0.17.1\n",
    "tqdm==4.66.1\n",
    "traitlets==5.9.0\n",
    "urllib3==2.0.4\n",
    "wcwidth==0.2.6\n",
    "yarl==1.9.2\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ pip install pandas\n",
    "Collecting pandas\n",
    "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
    "      12.3/12.3 MB 27.3 MB/s eta 0:00:00\n",
    "Collecting python-dateutil>=2.8.2\n",
    "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
    "      247.7/247.7 KB 10.3 MB/s eta 0:00:00\n",
    "Collecting pytz>=2020.1\n",
    "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
    "      502.5/502.5 KB 19.0 MB/s eta 0:00:00\n",
    "Collecting tzdata>=2022.1\n",
    "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
    "      341.8/341.8 KB 18.0 MB/s eta 0:00:00\n",
    "Collecting numpy>=1.22.4\n",
    "  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
    "      18.2/18.2 MB 32.5 MB/s eta 0:00:00\n",
    "Requirement already satisfied: six>=1.5 in ./lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
    "Installing collected packages: pytz, tzdata, python-dateutil, numpy, pandas\n",
    "Successfully installed numpy-1.26.0 pandas-2.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 tzdata-2023.3\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ pip freeze | grep pandas\n",
    "pandas==2.1.1\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ cp /mnt/c/Users/eyamr/Downloads/data.csv .\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ cp /mnt/c/Users/eyamr/Downloads/corr.py .\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ more corr.py\n",
    "# Reference: https://www.geeksforgeeks.org/create-a-correlation-matrix-using-python/\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create dataframe from file\n",
    "dataframe = pd.read_csv('data.csv')\n",
    "\n",
    "# Show dataframe\n",
    "#print(dataframe)\n",
    "\n",
    "# Use the corr() method on dataframe to create a correlation matrix\n",
    "matrix = dataframe.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "#print('The Correlation Matrix is: ')\n",
    "#print(matrix)\n",
    "\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 8,\n",
    "                       'display.width', 20000,\n",
    "                       ):\n",
    "    with open('correlation', 'w', encoding = 'utf8') as correlation:\n",
    "        correlation.write(str(matrix))\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ python corr.py\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ ls -la\n",
    "total 35676\n",
    "drwxr-xr-x 8 eyamrog eyamrog    32768 Oct  7 10:00 .\n",
    "drwxr-xr-x 3 eyamrog eyamrog     4096 Oct  3 11:25 ..\n",
    "drwxr-xr-x 2 eyamrog eyamrog     4096 Oct  7 09:23 bin\n",
    "-rwxr-xr-x 1 eyamrog eyamrog      718 Oct  7 09:58 corr.py\n",
    "-rw-r--r-- 1 eyamrog eyamrog 12017004 Oct  7 10:00 correlation\n",
    "-rwxr-xr-x 1 eyamrog eyamrog 24324000 Oct  7 09:26 data.csv\n",
    "-rw-r--r-- 1 eyamrog eyamrog      250 Oct  4 16:33 files\n",
    "drwxr-xr-x 2 eyamrog eyamrog    32768 Oct  4 16:26 images\n",
    "drwxr-xr-x 2 eyamrog eyamrog     4096 Aug 17 13:28 include\n",
    "drwxr-xr-x 2 eyamrog eyamrog    69632 Oct  4 16:33 labels\n",
    "-rw-r--r-- 1 eyamrog eyamrog     6911 Oct  4 16:37 labels.zip\n",
    "drwxr-xr-x 3 eyamrog eyamrog     4096 Aug 17 13:28 lib\n",
    "lrwxrwxrwx 1 eyamrog eyamrog        3 Aug 17 13:28 lib64 -> lib\n",
    "-rw-r--r-- 1 eyamrog eyamrog       71 Aug 17 13:28 pyvenv.cfg\n",
    "drwxr-xr-x 3 eyamrog eyamrog     4096 Aug 20 10:50 share\n",
    "-rwxr-xr-x 1 eyamrog eyamrog      225 Oct  3 12:43 vision.sh\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ cp correlation /mnt/c/Users/eyamr/Downloads/\n",
    "(my_env) eyamrog@RogLet-ASUS:~/environments/my_env$ deactivate\n",
    "eyamrog@RogLet-ASUS:~/environments/my_env$ logout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9bf9c-6aea-408c-8e53-573c881e253c",
   "metadata": {},
   "source": [
    "## 'formats' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7453c7f-7ef9-4542-a3c7-e3590c613d8b",
   "metadata": {},
   "source": [
    "- description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30cc0a5-132e-4add-996a-ae876350279c",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02bc06-aa5b-4613-b94d-042ebade9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "formats () {\n",
    "\n",
    "nlines=$( cat tweets/emoji.txt | wc -l | tr -dc '[0-9]' )\n",
    "\n",
    "tail +2 images/correlation | tr -s ' ' | sed 's/^/CORR /' > bottom\n",
    "head -1 images/correlation | tr -s ' ' | sed 's/^[ ]*//' | sed \"s/\\(v......\\)/$nlines/g\" | sed 's/^/N . /' > n\n",
    "\n",
    "sed 's;data.csv;images/data.csv;' std.py > p\n",
    "python3 p > s \n",
    "tr -s ' ' < s | cut -d' ' -f2 | grep -v 'float' | tr '\\n' ' ' | sed 's/^/STD\t . /' > std \n",
    "echo >> std\n",
    "\n",
    "sed 's;data.csv;images/data.csv;' mean.py > p\n",
    "python3 p > m \n",
    "tr -s ' ' < m | cut -d' ' -f2 | grep -v 'float' | tr '\\n' ' ' | sed 's/^/MEAN . /' > mean\n",
    "echo >> mean\n",
    "\n",
    "cat mean std n bottom > images/sas/corr.txt\n",
    "\n",
    "echo \"PROC FORMAT library=work ;\n",
    "  VALUE  \\$lexlabels\" > images/sas/word_labels_format.sas\n",
    "tr '\\t' ' ' < images/selectedwords | sed 's/\\(.*\\) \\(.*\\)/\"\\1\" = \"\\2\"/' | sed -e 's/&/and/g' -e 's/%/pc/g' >> images/sas/word_labels_format.sas\n",
    "echo \";\n",
    "run;\n",
    "quit;\" >> images/sas/word_labels_format.sas\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54cc81-d0c1-42ec-bdc6-a062de624ff6",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ddbd62-6c95-4d09-9080-536a59507a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdfcd11c-084f-430c-9d05-29e64a61634c",
   "metadata": {},
   "source": [
    "## 'examples' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848cb33-6c6a-427f-8421-72001fe5888d",
   "metadata": {},
   "source": [
    "- description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bd67b-8802-457d-92dd-7dee95f32b57",
   "metadata": {},
   "source": [
    "### Original function (Do not execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a631dc-0c2a-4a95-9b10-f6b96017c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples () {\n",
    "\n",
    "mkdir -p images/examples\n",
    "rm -f images/examples/*\n",
    "\n",
    "html2text -nobs images/sas/output_group\"$group\"_images/loadtable.html > a\n",
    "\n",
    "rm -f x??\n",
    "split -p'=====' a\n",
    "ls x?? > files\n",
    "\n",
    "while read file\n",
    "do\n",
    "      pole=$( grep '^Factor ' $file | cut -d' ' -f2,3 | sed -e 's/^/f/' -e 's/ //g' )\n",
    "      sed 's/^[ ]*//' $file | grep '^[0-9]' | tr -dc '[:alpha:][:punct:][0-9]\\n ' | sed 's/^/~/' | tr  '[:space:]()' ' ' | tr -s ' ' |  tr '~' '\\n' | cut -d' ' -f2 | grep -v '^$' | sed \"s/^/$pole /\" \n",
    "done < files > images/examples/factors\n",
    "\n",
    "\n",
    "rm -f x??\n",
    "\n",
    "head -1 images/sas/output_group\"$group\"_images/group4_images_scores.tsv | tr -d '\\r' | tr '\\t' '\\n' > vars\n",
    "    \n",
    "last=$( cut -d' ' -f1 images/examples/factors | tr -dc '[0-9\\n]' | sort -nr | head -1 )\n",
    "    \n",
    "for i in $(eval echo {1..$last});\n",
    "do\n",
    "      column=$( echo \" $i + 1 \" | bc ) \n",
    "      cut -f1,\"$column\" images/sas/output_group4_images/group4_images_scores_only.tsv  | tail +2 > a\n",
    "\n",
    "      for pole in pos neg\n",
    "      do\n",
    "        echo \"--- \"f\"$i\"\"$pole\"\" ---\" \n",
    "\n",
    "        if [ \"$pole\" == pos ] ; then\n",
    "           sort -nr -k2,2 a | grep -v '\\-' | tr '\\t' ' ' | grep -v ' 0' | head -20 | nl -nrz > files\n",
    "        else\n",
    "           sort -n -k2,2 a | grep '\\-' | tr '\\t' ' ' | grep -v ' 0' | grep -v '\t0' | head -20 | nl -nrz > files\n",
    "        fi\n",
    "\n",
    "        grep f\"$i\"\"$pole\" images/examples/factors | sort -t' ' -k2,2 | cut -d' ' -f2 | sort > factor_words\n",
    "        \n",
    "        while read n file score\n",
    "        do\n",
    "\n",
    "          grep -m1 $file images/sas/output_group4_images/group4_images_scores.tsv | tr -d '\\r' | tr '\\t' '\\n' > scores\n",
    "          paste vars scores | tr '\\t' ' ' | grep '^v' | grep -v ' 0$' | cut -d' ' -f1 | sort > vars_text\n",
    "          join vars_text images/selectedwords | cut -d' ' -f2 | sort > vars_text_codes\n",
    "          username=$( grep -w $file user_index.txt | cut -d' ' -f2 )\n",
    "          picture=$( grep -w $file images/images_index.txt | cut -d'|' -f2,7 | tr ':|' ' ' | cut -d' ' -f2,4 | sed 's;\\(.*\\) \\(.*\\);\\1.\\2;' )\n",
    "          folder=$( grep -w $file images/images_index.txt | cut -d'|' -f1 | tr ':|' ' ' | cut -d' ' -f2  )\n",
    "          url=$( grep -m1 -B5 $file tweets/jq.txt | grep '\"url\"'  | cut -d':' -f2- | tr -d '\",' | sed 's/^[ ]*//' )\n",
    "          extension=$( echo $picture | cut -d'.' -f2 )\n",
    "          cp images/images/$folder/$picture images/examples/image_f\"$i\"\"$pole\"_x`\"$n\".\"$extension\"\n",
    "\n",
    "          echo \"---------------\" \n",
    "\n",
    "          echo \"# $n\" \n",
    "          echo \"score = $score\"  \n",
    "          echo \"url: $url\"\n",
    "          echo\n",
    "\n",
    "          grep -w $file images/labels.txt | tr '|' '\\n' | sed 's/l:/~/' | tr '~' '\\n'    \n",
    "\n",
    "          echo\n",
    "          echo \"Lemmas in this picture that loaded on the factor:\"\n",
    "          echo\n",
    "\n",
    "          join vars_text_codes factor_words > ll\n",
    "          tr '\\n' ',' < ll | sed 's/,/, /g' | sed 's/, $//' > images/examples/lemmas_f\"$i\"_\"$pole\"_\"$n\".txt\n",
    "          cat ll\n",
    "\n",
    "          echo \n",
    "\n",
    "        done < files > images/examples/examples_f\"$i\"_\"$pole\".txt\n",
    "\n",
    "      done\n",
    "\n",
    "done\n",
    "\n",
    "    #rm -f vars factor_words scores vars_text vars_text_codes\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d53ca2-8c00-4235-95ee-51f4951fb974",
   "metadata": {},
   "source": [
    "### Executable from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc490f0-4a66-4790-b770-0c42e91f3777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
