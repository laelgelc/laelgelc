{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Replacing Unicode characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e585075d-1385-47f5-af17-22979a78e9df",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Unicode characters should be replaced by the corresponding ASCII ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3e700-9f85-4c6d-be36-b4268d7425a7",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4a8657-0245-4eaf-b11f-233891dc8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b7c11-eca7-4b21-8ad5-45626b1afb47",
   "metadata": {},
   "source": [
    "## Detecting Unicode characters in `True.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933bc0ff-cb6c-4bc3-b097-b199ccf01083",
   "metadata": {},
   "source": [
    "### Loading the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d6c4cad-4b6b-438c-a617-27a22f7afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14dbfa1-6752-4975-ad79-e2ccdbb2e9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21417 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "21412  'Fully committed' NATO backs new U.S. approach...   \n",
       "21413  LexisNexis withdrew two products from Chinese ...   \n",
       "21414  Minsk cultural hub becomes haven from authorities   \n",
       "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
       "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...     worldnews   \n",
       "21413  LONDON (Reuters) - LexisNexis, a provider of l...     worldnews   \n",
       "21414  MINSK (Reuters) - In the shadow of disused Sov...     worldnews   \n",
       "21415  MOSCOW (Reuters) - Vatican Secretary of State ...     worldnews   \n",
       "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...     worldnews   \n",
       "\n",
       "                     date  \n",
       "0      December 31, 2017   \n",
       "1      December 29, 2017   \n",
       "2      December 31, 2017   \n",
       "3      December 30, 2017   \n",
       "4      December 29, 2017   \n",
       "...                   ...  \n",
       "21412    August 22, 2017   \n",
       "21413    August 22, 2017   \n",
       "21414    August 22, 2017   \n",
       "21415    August 22, 2017   \n",
       "21416    August 22, 2017   \n",
       "\n",
       "[21417 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6363bf-2664-4c61-8ce2-14575cde9c3a",
   "metadata": {},
   "source": [
    "### Converting the dataframe into a JSON string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8610a0-ccd0-4aa1-9fc0-39150542d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_json = df_true.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972eb296-67f1-4707-b951-f55bd74ae2e2",
   "metadata": {},
   "source": [
    "### Detecting Unicode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baeab1b4-7050-4b5c-849e-767b190af4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character \\u2019: Count = 70808\n",
      "Character \\u00e9: Count = 50\n",
      "Character \\u2018: Count = 1195\n",
      "Character \\u00e1: Count = 23\n",
      "Character \\u00a0: Count = 5270\n",
      "Character \\u00bf: Count = 3\n",
      "Character \\u200b: Count = 2\n",
      "Character \\u201c: Count = 54140\n",
      "Character \\u201d: Count = 53861\n",
      "Character \\u2013: Count = 716\n",
      "Character \\u00f1: Count = 11\n",
      "Character \\u2014: Count = 503\n",
      "Character \\u00fa: Count = 2\n",
      "Character \\u2026: Count = 74\n",
      "Character \\u00e0: Count = 4\n",
      "Character \\u00ed: Count = 6\n",
      "Character \\u27a1: Count = 1\n",
      "Character \\ufe0f: Count = 4\n",
      "Character \\u00e7: Count = 5\n",
      "Character \\u00f6: Count = 1\n",
      "Character \\u00f3: Count = 9\n",
      "Character \\u2611: Count = 3\n",
      "Character \\u200e: Count = 9\n",
      "Character \\u200f: Count = 4\n",
      "Character \\u014d: Count = 2\n",
      "Character \\u00b0: Count = 1\n",
      "Character \\u00af: Count = 2\n",
      "Character \\u30c4: Count = 1\n",
      "Character \\u00fc: Count = 2\n",
      "Character \\u00b4: Count = 2\n",
      "Character \\u00ad: Count = 1\n",
      "Character \\u00ea: Count = 1\n",
      "Character \\u00f4: Count = 1\n",
      "Character \\u0101: Count = 10\n",
      "Character \\u00e2: Count = 1\n",
      "Character \\u200a: Count = 5\n",
      "Character \\u2022: Count = 3\n"
     ]
    }
   ],
   "source": [
    "def extract_unicode_characters(text):\n",
    "    # Define the RegEx pattern for matching Unicode characters\n",
    "    pattern = r'\\\\u[0-9A-Fa-f]{4}'\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    # Count the occurrences of each UNICODE character\n",
    "    char_count = Counter(matches)\n",
    "    \n",
    "    return char_count\n",
    "\n",
    "# Extract Unicode characters and their counts\n",
    "unicode_counts = extract_unicode_characters(true_json)\n",
    "\n",
    "# Print the results\n",
    "for char, count in unicode_counts.items():\n",
    "    print(f'Character {char}: Count = {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629624b2-2559-44df-a498-0a1085253057",
   "metadata": {},
   "source": [
    "## Detecting Unicode characters in `Fake.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a789e60-37d2-4ace-8fe3-1e6037eff43b",
   "metadata": {},
   "source": [
    "### Loading the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e70ba3f-7170-4699-a13a-a0622703a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7519e605-afb1-4858-890f-1076249f909b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 15, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 12, 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "23476  McPain: John McCain Furious That Iran Treated ...   \n",
       "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "23479  How to Blow $700 Million: Al Jazeera America F...   \n",
       "23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text      subject  \\\n",
       "0      Donald Trump just couldn t wish all Americans ...         News   \n",
       "1      House Intelligence Committee Chairman Devin Nu...         News   \n",
       "2      On Friday, it was revealed that former Milwauk...         News   \n",
       "3      On Christmas day, Donald Trump announced that ...         News   \n",
       "4      Pope Francis used his annual Christmas Day mes...         News   \n",
       "...                                                  ...          ...   \n",
       "23476  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n",
       "23477  21st Century Wire says It s a familiar theme. ...  Middle-east   \n",
       "23478  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n",
       "23479  21st Century Wire says Al Jazeera America will...  Middle-east   \n",
       "23480  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n",
       "\n",
       "                    date  \n",
       "0      December 31, 2017  \n",
       "1      December 31, 2017  \n",
       "2      December 30, 2017  \n",
       "3      December 29, 2017  \n",
       "4      December 25, 2017  \n",
       "...                  ...  \n",
       "23476   January 16, 2016  \n",
       "23477   January 16, 2016  \n",
       "23478   January 15, 2016  \n",
       "23479   January 14, 2016  \n",
       "23480   January 12, 2016  \n",
       "\n",
       "[23481 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a033f-152c-4c61-96a7-b7d0616d86fb",
   "metadata": {},
   "source": [
    "### Converting the dataframe into a JSON string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d295162-fc19-4ccc-9b59-2e71e486919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_json = df_fake.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d2d13-c0cf-476d-999d-66c2234c2224",
   "metadata": {},
   "source": [
    "### Detecting Unicode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e461074-9668-479b-bd55-5723ce2f01a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character \\u2019: Count = 13492\n",
      "Character \\u2018: Count = 3431\n",
      "Character \\u2014: Count = 76\n",
      "Character \\u2013: Count = 754\n",
      "Character \\u00ed: Count = 1\n",
      "Character \\u201c: Count = 5028\n",
      "Character \\u201d: Count = 5470\n",
      "Character \\u2026: Count = 4832\n",
      "Character \\u00e9: Count = 42\n",
      "Character \\u2122: Count = 1\n",
      "Character \\u202a: Count = 1\n",
      "Character \\u200e: Count = 1\n",
      "Character \\u202c: Count = 1\n",
      "Character \\u00a0: Count = 56\n",
      "Character \\u200b: Count = 1\n",
      "Character \\u2032: Count = 2\n",
      "Character \\u00f1: Count = 1\n",
      "Character \\u2033: Count = 1\n",
      "Character \\u20ac: Count = 4\n",
      "Character \\u00a3: Count = 2\n",
      "Character \\u00c9: Count = 2\n",
      "Character \\u00a1: Count = 2\n",
      "Character \\u00eb: Count = 3\n",
      "Character \\ufeff: Count = 1\n",
      "Character \\u00ad: Count = 2\n",
      "Character \\u017d: Count = 2\n",
      "Character \\u017e: Count = 2\n",
      "Character \\u0107: Count = 2\n",
      "Character \\u00e0: Count = 2\n",
      "Character \\u003d: Count = 2\n",
      "Character \\u0026: Count = 2\n",
      "Character \\u200B: Count = 1\n",
      "Character \\u2028: Count = 4\n",
      "Character \\u2029: Count = 4\n",
      "Character \\u000b: Count = 1\n",
      "Character \\uffff: Count = 3\n"
     ]
    }
   ],
   "source": [
    "def extract_unicode_characters(text):\n",
    "    # Define the RegEx pattern for matching Unicode characters\n",
    "    pattern = r'\\\\u[0-9A-Fa-f]{4}'\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    # Count the occurrences of each UNICODE character\n",
    "    char_count = Counter(matches)\n",
    "    \n",
    "    return char_count\n",
    "\n",
    "# Extract Unicode characters and their counts\n",
    "unicode_counts = extract_unicode_characters(fake_json)\n",
    "\n",
    "# Print the results\n",
    "for char, count in unicode_counts.items():\n",
    "    print(f'Character {char}: Count = {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065c274-37dc-434d-80cb-ed3bf613489a",
   "metadata": {},
   "source": [
    "## List of Identified Unicode characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3b867-4ab0-4bc4-8cb0-aa8b8c9a9e8a",
   "metadata": {},
   "source": [
    "[Unicode reference](https://www.compart.com/en/unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300af976-f596-4793-a850-7589fae9a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\u000b = <Line Tabulation> (VT)\n",
    "\\u0026 = Ampersand = &\n",
    "\\u003d = Equals Sign = =\n",
    "\\u00a0 = No-Break Space (NBSP)\n",
    "\\u00a1 = Inverted Exclamation Mark = ¡\n",
    "\\u00a3 = Pound Sign = £\n",
    "\\u00ad = Soft Hyphen (SHY)\n",
    "\\u00af = Macron = ¯\n",
    "\\u00b0 = Degree Sign = °\n",
    "\\u00b4 = Acute Accent = ´\n",
    "\\u00bf = Inverted Question Mark = ¿\n",
    "\\u00c9 = Latin Capital Letter E with Acute = É\n",
    "\\u00e0 = Latin Small Letter A with Grave = à\n",
    "\\u00e1 = Latin Small Letter A with Acute = á\n",
    "\\u00e2 = Latin Small Letter A with Circumflex = â\n",
    "\\u00e7 = Latin Small Letter C with Cedilla = ç\n",
    "\\u00e9 = Latin Small Letter E with Acute = é\n",
    "\\u00ea = Latin Small Letter E with Circumflex = ê\n",
    "\\u00eb = Latin Small Letter E with Diaeresis = ë\n",
    "\\u00ed = Latin Small Letter I with Acute = í\n",
    "\\u00f1 = Latin Small Letter N with Tilde = ñ\n",
    "\\u00f3 = Latin Small Letter O with Acute = ó\n",
    "\\u00f4 = Latin Small Letter O with Circumflex = ô\n",
    "\\u00f6 = Latin Small Letter O with Diaeresis = ö\n",
    "\\u00fa = Latin Small Letter U with Acute = ú\n",
    "\\u00fc = Latin Small Letter U with Diaeresis = ü\n",
    "\\u0101 = Latin Small Letter A with Macron = ā\n",
    "\\u0107 = Latin Small Letter C with Acute = ć\n",
    "\\u014d = Latin Small Letter O with Macron = ō\n",
    "\\u017d = Latin Capital Letter Z with Caron = Ž\n",
    "\\u017e = Latin Small Letter Z with Caron = ž\n",
    "\\u200a = Hair Space = ' '\n",
    "\\u200b = Zero Width Space (ZWSP) = ' '\n",
    "\\u200B = Zero Width Space (ZWSP) = ' '\n",
    "\\u200e = Left-to-Right Mark (LRM)\n",
    "\\u200f = Right-to-Left Mark (RLM)\n",
    "\\u2013 = En Dash = –\n",
    "\\u2014 = Em Dash = —\n",
    "\\u2018 = Left Single Quotation Mark = '\n",
    "\\u2019 = Right Single Quotation Mark = '\n",
    "\\u201c = Left Double Quotation Mark = \"\n",
    "\\u201d = Right Double Quotation Mark = \"\n",
    "\\u2022 = Bullet = •\n",
    "\\u2026 = Horizontal Ellipsis = …\n",
    "\\u2028 = Line Separator = (LS)\n",
    "\\u2029 = Paragraph Separator = (PS)\n",
    "\\u202a = Left-to-Right Embedding (LRE)\n",
    "\\u202c = Pop Directional Formatting (PDF)\n",
    "\\u2032 = Prime = '\n",
    "\\u2033 = Double Prime = ''\n",
    "\\u20ac = Euro Sign = €\n",
    "\\u2122 = Trade Mark Sign = (TM)\n",
    "\\u2611 = Ballot Box with Check = ☑\n",
    "\\u27a1 = Black Rightwards Arrow = ➡\n",
    "\\u30c4 = Katakana Letter Tu = ツ\n",
    "\\ufe0f = Variation Selector-16 (VS16) = ◌️\n",
    "\\ufeff = Zero Width No-Break Space (BOM, ZWNBSP)\n",
    "\\uffff = Undefined Character\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff2abb7-35d2-44a7-ab50-91dad09575ae",
   "metadata": {},
   "source": [
    "## Replacing Unicode characters in `True.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae44114-2d64-4b85-804f-8986a7f5e09f",
   "metadata": {},
   "source": [
    "Note:\n",
    "- The characters `\\u201c` and `\\u201d` correspond to `double quotation marks` which are delimiters of a JSON file - their replacement cause malformation of the file - they need to be replaced manually via Visual Studio Code `replace` functionality;\n",
    "- The characters `\\u000b`, `\\u0026`, `\\u003d`, `\\u00a0`, `\\u2028`, `\\u2029, `\\u200B` and `\\uffff` are problematic, especially in the case of `Fake.csv`. They do not exist in `True.csv` except `\\u00a0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "394f8797-eb77-47ed-9066-89cd12f522bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_json_replaced_Unicode = re.sub(r'\\\\u000b', ' ', true_json)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u0026', '&', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u003d', '=', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00a0', ' ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00a1', '¡', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00a3', '£', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00ad', ' ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00af', '¯', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00b0', '°', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00b4', '´', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00bf', '¿', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00c9', 'É', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00e0', 'à', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00e1', 'á', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00e2', 'â', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00e7', 'ç', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00e9', 'é', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00ea', 'ê', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00eb', 'ë', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00ed', 'í', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00f1', 'ñ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00f3', 'ó', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00f4', 'ô', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00f6', 'ö', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00fa', 'ú', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u00fc', 'ü', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u0101', 'ā', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u0107', 'ć', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u014d', 'ō', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u017d', 'Ž', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u017e', 'ž', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u200a', ' ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u200b', ' ', true_json_replaced_Unicode)\n",
    "#true_json_replaced_Unicode = re.sub(r'\\\\u200B', ' ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u200e', ' ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u200f', ' ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2013', '–', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2014', '—', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2018', \"'\", true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2019', \"'\", true_json_replaced_Unicode)\n",
    "#true_json_replaced_Unicode = re.sub(r'\\\\u201c', '\"', true_json_replaced_Unicode)\n",
    "#true_json_replaced_Unicode = re.sub(r'\\\\u201d', '\"', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2022', '•', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2026', '…', true_json_replaced_Unicode)\n",
    "#true_json_replaced_Unicode = re.sub(r'\\\\u2028', '(LS)', true_json_replaced_Unicode)\n",
    "#true_json_replaced_Unicode = re.sub(r'\\\\u2029', '(PS)', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u202a', '(LRE)', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u202c', ' ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2032', \"'\", true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2033', \"''\", true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u20ac', '€', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2122', '(TM)', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u2611', '☑', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u27a1', '➡', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\u30c4', 'ツ', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\ufe0f', '◌️', true_json_replaced_Unicode)\n",
    "true_json_replaced_Unicode = re.sub(r'\\\\ufeff', ' ', true_json_replaced_Unicode)\n",
    "#true_json_replaced_Unicode = re.sub(r'\\\\uffff', ' ', true_json_replaced_Unicode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b163efd-0503-41cf-8180-10412011a6b4",
   "metadata": {},
   "source": [
    "### Loading the JSON file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b95ff9-0a48-40ff-ba5c-274069121317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true_json_replaced_Unicode = pd.read_json(StringIO(true_json_replaced_Unicode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2261883-5986-42e0-85cd-6e8511b4118c",
   "metadata": {},
   "source": [
    "### Exporting the dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b259093-4737-40e3-9091-cb320b7a43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true_json_replaced_Unicode.to_csv('True_replaced_Unicode.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a410fbc-c14e-4a64-b432-1e5b283ba8a4",
   "metadata": {},
   "source": [
    "## Replacing Unicode characters in `Fake.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1241141-794e-4791-92cc-9867f40d12bf",
   "metadata": {},
   "source": [
    "Note:\n",
    "- The characters `\\u201c` and `\\u201d` correspond to `double quotation marks` which are delimiters of a JSON file - their replacement cause malformation of the file - they need to be replaced manually via Visual Studio Code `replace` functionality;\n",
    "- The characters `\\u000b`, `\\u0026`, `\\u003d`, `\\u00a0`, `\\u2028`, `\\u2029, `\\u200B` and `\\uffff` are problematic, especially in the case of `Fake.csv`. They do not exist in `True.csv` except `\\u00a0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1607873-d911-41e1-9120-efadeeab73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u000b', ' ', fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u0026', '&', fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u003d', '=', fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u00a0', ' ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00a1', '¡', fake_json)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00a3', '£', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00ad', ' ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00af', '¯', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00b0', '°', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00b4', '´', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00bf', '¿', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00c9', 'É', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00e0', 'à', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00e1', 'á', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00e2', 'â', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00e7', 'ç', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00e9', 'é', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00ea', 'ê', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00eb', 'ë', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00ed', 'í', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00f1', 'ñ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00f3', 'ó', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00f4', 'ô', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00f6', 'ö', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00fa', 'ú', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u00fc', 'ü', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u0101', 'ā', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u0107', 'ć', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u014d', 'ō', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u017d', 'Ž', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u017e', 'ž', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u200a', ' ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u200b', ' ', fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u200B', ' ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u200e', ' ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u200f', ' ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2013', '–', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2014', '—', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2018', \"'\", fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2019', \"'\", fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u201c', '\"', fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u201d', '\"', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2022', '•', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2026', '…', fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u2028', '(LS)', fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\u2029', '(PS)', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u202a', '(LRE)', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u202c', ' ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2032', \"'\", fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2033', \"''\", fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u20ac', '€', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2122', '(TM)', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u2611', '☑', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u27a1', '➡', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\u30c4', 'ツ', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\ufe0f', '◌️', fake_json_replaced_Unicode)\n",
    "fake_json_replaced_Unicode = re.sub(r'\\\\ufeff', ' ', fake_json_replaced_Unicode)\n",
    "#fake_json_replaced_Unicode = re.sub(r'\\\\uffff', ' ', fake_json_replaced_Unicode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ad7c5-b720-4442-bfc9-d2c3149f217d",
   "metadata": {},
   "source": [
    "### Loading the JSON file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab555aef-50cc-4e36-bf9d-818c108fe853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_json_replaced_Unicode = pd.read_json(StringIO(fake_json_replaced_Unicode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29fe57-c269-4390-882d-0e6806141a02",
   "metadata": {},
   "source": [
    "### Exporting the dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c78c203a-09c5-4e87-93a4-a98648870a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_json_replaced_Unicode.to_csv('Fake_replaced_Unicode.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bb7d9-6c68-44d5-9a15-3cee643f5a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
